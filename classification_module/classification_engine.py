#!/usr/bin/env python3
"""
–î–≤–∏–∂–æ–∫ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ –∑–≤–æ–Ω–∫–æ–≤ —Å –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–µ–π –æ–±—É—á–µ–Ω–∏—è
"""

import os
import re
import requests
import pandas as pd
import time
import hashlib
from datetime import datetime, timedelta
from pathlib import Path
from openpyxl.styles import PatternFill, Font, Border, Side, Alignment
from openpyxl.utils import get_column_letter
try:
    from .training_examples import TrainingExamplesManager
    from .classification_rules import ClassificationRulesManager
except ImportError:
    from training_examples import TrainingExamplesManager
    from classification_rules import ClassificationRulesManager
import json
import shutil
import tempfile

class CallClassificationEngine:
    """–î–≤–∏–∂–æ–∫ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ –∑–≤–æ–Ω–∫–æ–≤ —Å –¥–æ–æ–±—É—á–µ–Ω–∏–µ–º"""
    
    def __init__(
        self,
        api_key=None,
        base_url=None,
        model=None,
        training_db_path="training_examples.db",
        rules_db_path="classification_rules.db",
        station_names=None,
        station_mapping=None,
    ):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –¥–≤–∏–∂–∫–∞ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏.

        –ü–∞—Ä–∞–º–µ—Ç—Ä—ã:
        - api_key: –∫–ª—é—á –¥–æ—Å—Ç—É–ø–∞ –∫ LLM (–µ—Å–ª–∏ –Ω–µ –ø–µ—Ä–µ–¥–∞–Ω, –±–µ—Ä—ë—Ç—Å—è –∏–∑ –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π –æ–∫—Ä—É–∂–µ–Ω–∏—è THEBAI_API_KEY)
        - base_url: –±–∞–∑–æ–≤—ã–π URL LLM (–µ—Å–ª–∏ –Ω–µ –ø–µ—Ä–µ–¥–∞–Ω, –±–µ—Ä—ë—Ç—Å—è –∏–∑ THEBAI_URL –∏–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è https://api.deepseek.com/v1)
        - model: –∏–º—è –º–æ–¥–µ–ª–∏ (–µ—Å–ª–∏ –Ω–µ –ø–µ—Ä–µ–¥–∞–Ω–æ, –±–µ—Ä—ë—Ç—Å—è –∏–∑ THEBAI_MODEL –∏–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è deepseek-chat)
        """
        # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ API –∫–ª–∏–µ–Ω—Ç–∞ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é ‚Äî DeepSeek —Å–æ–≤–º–µ—Å—Ç–∏–º—ã–π endpoint)
        api_key = api_key or os.getenv("THEBAI_API_KEY", "")
        base_url = base_url or os.getenv("THEBAI_URL", "https://api.deepseek.com/v1/chat/completions")
        self.model = model or os.getenv("THEBAI_MODEL", "deepseek-chat")
        self.api_key = api_key
        self.base_url = base_url
        self.debug_log_path = Path(rules_db_path).resolve().parent / "classification_llm_debug.log"
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –º–µ–Ω–µ–¥–∂–µ—Ä –æ–±—É—á–µ–Ω–∏—è
        self.training_manager = TrainingExamplesManager(db_path=training_db_path)
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –º–µ–Ω–µ–¥–∂–µ—Ä –ø—Ä–∞–≤–∏–ª –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏
        self.rules_manager = ClassificationRulesManager(db_path=rules_db_path)
        
        # –°–ª–æ–≤–∞—Ä—å –¥–ª—è –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è –Ω–æ–º–µ—Ä–æ–≤ —Å—Ç–∞–Ω—Ü–∏–π –≤ –Ω–∞–∑–≤–∞–Ω–∏—è
        self.STATION_CODES = {
            '9322': '–ë—Ä–Ω', '4231': '–ë—Ä–Ω', '4230': '–ë—Ä–Ω',
            '9326': '–†–ø–±', '4160': '–†–ø–±',
            '9347': '–†–æ–¥', '4254': '–†–æ–¥', '4255': '–†–æ–¥',
            '9327': '–ß–æ–Ω', '4210': '–ß–æ–Ω', '4211': '–ß–æ–Ω',
            '9325': '–ß–æ–Ω –ö', '4217': '–ß–æ–Ω –ö',
            '9300': '–°–∞—Ö', '4222': '–°–∞—Ö', '4221': '–°–∞—Ö',
            '9321': '–ö–º–Ω', '4200': '–ö–º–Ω', '4201': '–ö–º–Ω',
            '9324': '–•–ª–∑', '4240': '–•–ª–∑',
            '9344': '–ö–±—à', '4253': '–ö–±—à', '4256': '–ö–±—à',
            '9304': '–î–∑—Ä', '4100': '–î–∑—Ä', '4101': '–î–∑—Ä',
            '9308': '–ê—Ä–∑', '4110': '–ê—Ä–∑', '4111': '–ê—Ä–∑',
            '9301': '–í–ª–¥', '4140': '–í–ª–¥', '4141': '–í–ª–¥',
            '9302': '–ö–∑–Ω–ò', '4155': '–ö–∑–Ω–ò', '4156': '–ö–∑–Ω–ò',
            '9307': '–ö–∑–Ω–°', '4150': '–ö–∑–Ω–°', '5151': '–ö–∑–Ω–°',
            '9350': '–†–¥–Ω', '4257': '–†–¥–Ω', '4258': '–†–¥–Ω',
            '9316': '–ú–µ—á', '4170': '–ú–µ—á', '4172': '–ú–µ—á',
            '9319': '–¢–≥–Ω', '4181': '–¢–≥–Ω', '4180': '–¢–≥–Ω'
        }

        # –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–µ —Å—Ç–∞–Ω—Ü–∏–∏ –∏–∑ –õ–ö –∏–º–µ—é—Ç –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç.
        user_station_codes = {}
        if isinstance(station_names, dict):
            for code, name in station_names.items():
                code_s = str(code).strip()
                name_s = str(name or code).strip()
                if code_s and name_s:
                    user_station_codes[code_s] = name_s
            if user_station_codes:
                self.STATION_CODES.update(user_station_codes)
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –∫–æ–¥—ã —Å—Ç–∞–Ω—Ü–∏–π –∏–∑ –Ω–∞—Å—Ç—Ä–æ–µ–∫ (–µ—Å–ª–∏ –∑–∞–¥–∞–Ω—ã)
        try:
            extra_codes_json = self.rules_manager.get_setting('station_codes_extra', '')
            if extra_codes_json:
                extra_codes = json.loads(extra_codes_json)
                if isinstance(extra_codes, dict):
                    # –ö–ª—é—á–∏ –≤—Å–µ–≥–¥–∞ –ø—Ä–∏–≤–æ–¥–∏–º –∫ —Å—Ç—Ä–æ–∫–∞–º, —á—Ç–æ–±—ã –Ω–µ –∑–∞–≤–∏—Å–µ—Ç—å –æ—Ç —Ç–∏–ø–∞ –≤ JSON
                    self.STATION_CODES.update({str(k): v for k, v in extra_codes.items()})
        except Exception:
            # –ü—Ä–∏ –æ—à–∏–±–∫–µ –Ω–∞—Å—Ç—Ä–æ–µ–∫ –ø—Ä–æ–¥–æ–ª–∂–∞–µ–º —Å –±–∞–∑–æ–≤—ã–º –Ω–∞–±–æ—Ä–æ–º –∫–æ–¥–æ–≤
            pass
        
        # –°—Ç–∞–Ω—Ü–∏–∏, –∫–æ—Ç–æ—Ä—ã–µ –Ω—É–∂–Ω–æ –∏—Å–∫–ª—é—á–∏—Ç—å –∏–∑ –ø—Ä–æ–µ–∫—Ç–∞
        # –ê—Ä–∑  - –ê—Ä–∑–∞–º–∞—Å
        # –•–ª–∑  - –•–∞–ª—å–∑–æ–≤—Å–∫–∞—è
        # –†–ø–±  - –†–µ—Å–ø—É–±–ª–∏–∫–∞–Ω—Å–∫–∞—è
        self.EXCLUDED_STATIONS = ['–ê—Ä–∑', '–•–ª–∑', '–†–ø–±']
        
        # –í—Å–µ —Å—Ç–∞–Ω—Ü–∏–∏ –≤ –ø—Ä–∞–≤–∏–ª—å–Ω–æ–º –ø–æ—Ä—è–¥–∫–µ (–±–µ–∑ –∏—Å–∫–ª—é—á–µ–Ω–Ω—ã—Ö)
        self.ALL_STATIONS = ['–ß–æ–Ω', '–ß–æ–Ω –ö', '–°–∞—Ö', '–†–æ–¥', '–ë—Ä–Ω', '–ö–º–Ω', '–ö–±—à', '–î–∑—Ä', '–ú–µ—á', '–¢–≥–Ω', '–í–ª–¥', '–ö–∑–Ω–ò', '–ö–∑–Ω–°', '–†–¥–Ω']

        # –ü—Ä–∏–≤—è–∑–∫–∞ –ø–æ–¥—Å—Ç–∞–Ω—Ü–∏–π –∫ –æ—Å–Ω–æ–≤–Ω—ã–º —Å—Ç–∞–Ω—Ü–∏—è–º –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è.
        if isinstance(station_mapping, dict):
            for main_code, sub_codes in station_mapping.items():
                main_code_s = str(main_code).strip()
                if not main_code_s:
                    continue
                main_name = self.STATION_CODES.get(main_code_s, main_code_s)
                for sub_code in (sub_codes or []):
                    sub_code_s = str(sub_code).strip()
                    if sub_code_s:
                        self.STATION_CODES[sub_code_s] = main_name

        # –î–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏—Ö –ø—Ä–æ—Ñ–∏–ª–µ–π —É–±–∏—Ä–∞–µ–º legacy-–∏—Å–∫–ª—é—á–µ–Ω–∏—è –∏ —Ñ–æ—Ä–º–∏—Ä—É–µ–º –ø–æ—Ä—è–¥–æ–∫ —Å—Ç–∞–Ω—Ü–∏–π.
        if user_station_codes:
            station_order = []
            seen = set()
            for _, station_name in sorted(user_station_codes.items(), key=lambda item: item[0]):
                if station_name not in seen:
                    seen.add(station_name)
                    station_order.append(station_name)
            if station_order:
                self.ALL_STATIONS = station_order
            self.EXCLUDED_STATIONS = []
        
        # –ù–æ–≤–∞—è —Å—Ö–µ–º–∞ –∫–∞—Ç–µ–≥–æ—Ä–∏–π —Å–æ–≥–ª–∞—Å–Ω–æ Google Sheets
        # –ù–æ–≤–∞—è —Å—Ö–µ–º–∞ –∫–∞—Ç–µ–≥–æ—Ä–∏–π —Å–æ–≥–ª–∞—Å–Ω–æ –¢–ó v1.0
        self.NEW_CATEGORIES = {
            "IN.NE": "–í—Ö–æ–¥—è—â–∏–µ - –ù–µ —Ü–µ–ª–µ–≤—ã–µ",
            "IN.CONS.MSG": "–í—Ö–æ–¥—è—â–∏–µ - –¶–µ–ª–µ–≤—ã–µ - –ö–æ–Ω—Å—É–ª—å—Ç–∞—Ü–∏—è - –ü–ï–†–ï–®–õ–ò –í –ú–ï–°–°–ï–ù–î–ñ–ï–†",
            "IN.CONS.REDIR": "–í—Ö–æ–¥—è—â–∏–µ - –¶–µ–ª–µ–≤—ã–µ - –ö–æ–Ω—Å—É–ª—å—Ç–∞—Ü–∏—è - –ü–ï–†–ï–ê–î–†–ï–°–ê–¶–ò–Ø",
            "IN.CONS.OWN": "–í—Ö–æ–¥—è—â–∏–µ - –¶–µ–ª–µ–≤—ã–µ - –ö–æ–Ω—Å—É–ª—å—Ç–∞—Ü–∏—è - –°–í–û–ò –ó–ê–ü–ß–ê–°–¢–ò",
            "IN.CONS.THINK": "–í—Ö–æ–¥—è—â–∏–µ - –¶–µ–ª–µ–≤—ã–µ - –ö–æ–Ω—Å—É–ª—å—Ç–∞—Ü–∏—è - –ü–û–î–£–ú–ê–ï–¢/–û–¢–ö–ê–ó",
            "IN.CONS.BUSY": "–í—Ö–æ–¥—è—â–∏–µ - –¶–µ–ª–µ–≤—ã–µ - –ö–æ–Ω—Å—É–ª—å—Ç–∞—Ü–∏—è - –ù–ï–¢ –í–†–ï–ú–ï–ù–ò/–ó–ê–ù–Ø–¢–û",
            "IN.CONS.COST": "–í—Ö–æ–¥—è—â–∏–µ - –¶–µ–ª–µ–≤—ã–µ - –ö–æ–Ω—Å—É–ª—å—Ç–∞—Ü–∏—è - –í–´–°–û–ö–ê–Ø –°–¢–û–ò–ú–û–°–¢–¨",
            "IN.CONS.NODO": "–í—Ö–æ–¥—è—â–∏–µ - –¶–µ–ª–µ–≤—ã–µ - –ö–æ–Ω—Å—É–ª—å—Ç–∞—Ü–∏—è - –ù–ï –í–´–ü–û–õ–ù–Ø–ï–ú –†–ê–ë–û–¢–´",
            "IN.CONS.CB": "–í—Ö–æ–¥—è—â–∏–µ - –¶–µ–ª–µ–≤—ã–µ - –ö–æ–Ω—Å—É–ª—å—Ç–∞—Ü–∏—è - –ó–ê–ü–õ–ê–ù–ò–†–û–í–ê–ù –ü–ï–†–ï–ó–í–û–ù",
            "IN.CONS.OTHER": "–í—Ö–æ–¥—è—â–∏–µ - –¶–µ–ª–µ–≤—ã–µ - –ö–æ–Ω—Å—É–ª—å—Ç–∞—Ü–∏—è - –û–±—â–∞—è",
            "IN.BOOK": "–í—Ö–æ–¥—è—â–∏–µ - –¶–µ–ª–µ–≤—ã–µ - –ó–∞–ø–∏—Å—å",
            "IN.FU.BOOK": "–í—Ö–æ–¥—è—â–∏–µ - –¶–µ–ª–µ–≤—ã–µ - –ü–æ—Å–ª–µ–¥—É—é—â–∏–π –∫–æ–Ω—Ç–∞–∫—Ç —Å –∑–∞–ø–∏—Å—å—é",
            "IN.INFO.FU.NOBOOK": "–í—Ö–æ–¥—è—â–∏–µ - –°–ø—Ä–∞–≤–æ—á–Ω—ã–µ - –ü–æ—Å–ª–µ–¥—É—é—â–∏–π –∫–æ–Ω—Ç–∞–∫—Ç –±–µ–∑ –∑–∞–ø–∏—Å–∏",
            "OUT.NE": "–ò—Å—Ö–æ–¥—è—â–∏–µ - –ù–µ —Ü–µ–ª–µ–≤—ã–µ",
            "OUT.CONS.MSG": "–ò—Å—Ö–æ–¥—è—â–∏–µ - –¶–µ–ª–µ–≤—ã–µ - –ö–æ–Ω—Å—É–ª—å—Ç–∞—Ü–∏—è - –ü–ï–†–ï–®–õ–ò –í –ú–ï–°–°–ï–ù–î–ñ–ï–†",
            "OUT.CONS.REDIR": "–ò—Å—Ö–æ–¥—è—â–∏–µ - –¶–µ–ª–µ–≤—ã–µ - –ö–æ–Ω—Å—É–ª—å—Ç–∞—Ü–∏—è - –ü–ï–†–ï–ê–î–†–ï–°–ê–¶–ò–Ø",
            "OUT.CONS.OWN": "–ò—Å—Ö–æ–¥—è—â–∏–µ - –¶–µ–ª–µ–≤—ã–µ - –ö–æ–Ω—Å—É–ª—å—Ç–∞—Ü–∏—è - –°–í–û–ò –ó–ê–ü–ß–ê–°–¢–ò",
            "OUT.CONS.THINK": "–ò—Å—Ö–æ–¥—è—â–∏–µ - –¶–µ–ª–µ–≤—ã–µ - –ö–æ–Ω—Å—É–ª—å—Ç–∞—Ü–∏—è - –ü–û–î–£–ú–ê–ï–¢/–û–¢–ö–ê–ó",
            "OUT.CONS.BUSY": "–ò—Å—Ö–æ–¥—è—â–∏–µ - –¶–µ–ª–µ–≤—ã–µ - –ö–æ–Ω—Å—É–ª—å—Ç–∞—Ü–∏—è - –ù–ï–¢ –í–†–ï–ú–ï–ù–ò/–ó–ê–ù–Ø–¢–û",
            "OUT.CONS.COST": "–ò—Å—Ö–æ–¥—è—â–∏–µ - –¶–µ–ª–µ–≤—ã–µ - –ö–æ–Ω—Å—É–ª—å—Ç–∞—Ü–∏—è - –í–´–°–û–ö–ê–Ø –°–¢–û–ò–ú–û–°–¢–¨",
            "OUT.CONS.NODO": "–ò—Å—Ö–æ–¥—è—â–∏–µ - –¶–µ–ª–µ–≤—ã–µ - –ö–æ–Ω—Å—É–ª—å—Ç–∞—Ü–∏—è - –ù–ï –í–´–ü–û–õ–ù–Ø–ï–ú –†–ê–ë–û–¢–´",
            "OUT.CONS.CB": "–ò—Å—Ö–æ–¥—è—â–∏–µ - –¶–µ–ª–µ–≤—ã–µ - –ö–æ–Ω—Å—É–ª—å—Ç–∞—Ü–∏—è - –ó–ê–ü–õ–ê–ù–ò–†–û–í–ê–ù –ü–ï–†–ï–ó–í–û–ù",
            "OUT.CONS.OTHER": "–ò—Å—Ö–æ–¥—è—â–∏–µ - –¶–µ–ª–µ–≤—ã–µ - –ö–æ–Ω—Å—É–ª—å—Ç–∞—Ü–∏—è - –û–±—â–∞—è",
            "OUT.BOOK": "–ò—Å—Ö–æ–¥—è—â–∏–µ - –¶–µ–ª–µ–≤—ã–µ - –ó–∞–ø–∏—Å—å",
            "OUT.FU.BOOK": "–ò—Å—Ö–æ–¥—è—â–∏–µ - –¶–µ–ª–µ–≤—ã–µ - –ü–æ—Å–ª–µ–¥—É—é—â–∏–π –∫–æ–Ω—Ç–∞–∫—Ç —Å –∑–∞–ø–∏—Å—å—é",
            "OUT.INFO.FU.NOBOOK": "–ò—Å—Ö–æ–¥—è—â–∏–µ - –°–ø—Ä–∞–≤–æ—á–Ω—ã–µ - –ü–æ—Å–ª–µ–¥—É—é—â–∏–π –∫–æ–Ω—Ç–∞–∫—Ç –±–µ–∑ –∑–∞–ø–∏—Å–∏",
            "OUT.OBZ.BOOK": "–ò—Å—Ö–æ–¥—è—â–∏–µ - –û–±–∑–≤–æ–Ω - –° –∑–∞–ø–∏—Å—å—é",
            "OUT.OBZ.NOBOOK": "–ò—Å—Ö–æ–¥—è—â–∏–µ - –û–±–∑–≤–æ–Ω - –ë–µ–∑ –∑–∞–ø–∏—Å–∏"
        }
        
        # –°–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ —Å—Ç–∞—Ä—ã—Ö –∫–∞—Ç–µ–≥–æ—Ä–∏–π –Ω–æ–≤—ã–º (–¥–ª—è –æ–±—Ä–∞—Ç–Ω–æ–π —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏)
        self.LEGACY_TO_NEW_MAPPING = {
            "1": "1",   # –ù–ï –¶–ï–õ–ï–í–û–ô -> –í—Ö–æ–¥—è—â–∏–µ - –ù–µ —Ü–µ–ª–µ–≤—ã–µ
            "2": "11",  # –ó–ê–ü–ò–°–¨ –ù–ê –°–ï–†–í–ò–° -> –í—Ö–æ–¥—è—â–∏–µ - –¶–µ–ª–µ–≤—ã–µ - –ó–∞–ø–∏—Å—å
            "3": "2",   # –ö–û–ù–°–£–õ–¨–¢–ê–¶–ò–Ø -> –í—Ö–æ–¥—è—â–∏–µ - –¶–µ–ª–µ–≤—ã–µ - –ö–æ–Ω—Å—É–ª—å—Ç–∞—Ü–∏—è
            "4": "6",   # –ü–û–î–£–ú–ê–ï–¢/–û–¢–ö–ê–ó -> –í—Ö–æ–¥—è—â–∏–µ - –¶–µ–ª–µ–≤—ã–µ - –ü–û–î–£–ú–ê–ï–¢/–û–¢–ö–ê–ó
            "5": "7",   # –ù–ï–¢ –í–†–ï–ú–ï–ù–ò/–ó–ê–ù–Ø–¢–û -> –í—Ö–æ–¥—è—â–∏–µ - –¶–µ–ª–µ–≤—ã–µ - –ù–ï–¢ –í–†–ï–ú–ï–ù–ò/–ó–ê–ù–Ø–¢–û
            "6": "8",   # –í–´–°–û–ö–ê–Ø –°–¢–û–ò–ú–û–°–¢–¨ -> –í—Ö–æ–¥—è—â–∏–µ - –¶–µ–ª–µ–≤—ã–µ - –í–´–°–û–ö–ê–Ø –°–¢–û–ò–ú–û–°–¢–¨
            "7": "5",   # –°–í–û–ò –ó–ê–ü–ß–ê–°–¢–ò -> –í—Ö–æ–¥—è—â–∏–µ - –¶–µ–ª–µ–≤—ã–µ - –°–í–û–ò –ó–ê–ü–ß–ê–°–¢–ò
            "8": "9",   # –ù–ï –í–´–ü–û–õ–ù–Ø–ï–ú –†–ê–ë–û–¢–´ -> –í—Ö–æ–¥—è—â–∏–µ - –¶–µ–ª–µ–≤—ã–µ - –ù–ï –í–´–ü–û–õ–ù–Ø–ï–ú –†–ê–ë–û–¢–´
            "9": "3",   # –ü–ï–†–ï–®–õ–ò –í –ú–ï–°–°–ï–ù–î–ñ–ï–† -> –í—Ö–æ–¥—è—â–∏–µ - –¶–µ–ª–µ–≤—ã–µ - –ü–ï–†–ï–®–õ–ò –í –ú–ï–°–°–ï–ù–î–ñ–ï–†
            "10": "10", # –ó–ê–ü–õ–ê–ù–ò–†–û–í–ê–ù –ü–ï–†–ï–ó–í–û–ù -> –í—Ö–æ–¥—è—â–∏–µ - –¶–µ–ª–µ–≤—ã–µ - –ó–ê–ü–õ–ê–ù–ò–†–û–í–ê–ù –ü–ï–†–ï–ó–í–û–ù
            "11": "4",  # –ü–ï–†–ï–ê–î–†–ï–°–ê–¶–ò–Ø -> –í—Ö–æ–¥—è—â–∏–µ - –¶–µ–ª–µ–≤—ã–µ - –ü–ï–†–ï–ê–î–†–ï–°–ê–¶–ò–Ø
            "12": "14", # –û–ë–ó–í–û–ù -> –ò—Å—Ö–æ–¥—è—â–∏–µ - –ù–µ —Ü–µ–ª–µ–≤—ã–µ
            "13": "12", # –ü–û–°–õ–ï–î–£–Æ–©–ò–ô –ö–û–ù–¢–ê–ö–¢ -> –í—Ö–æ–¥—è—â–∏–µ - –¶–µ–ª–µ–≤—ã–µ - –ü–æ—Å–ª–µ–¥—É—é—â–∏–π –∫–æ–Ω—Ç–∞–∫—Ç —Å –∑–∞–ø–∏—Å—å—é
            "14": "1"   # –î–†–£–ì–û–ï -> –í—Ö–æ–¥—è—â–∏–µ - –ù–µ —Ü–µ–ª–µ–≤—ã–µ
        }
        
        # –ì—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∞ –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è
        # –ì—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∞ –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è
        self.CATEGORY_GROUPS = {
            "IN.NE": "–ù–µ —Ü–µ–ª–µ–≤—ã–µ",
            "IN.CONS.MSG": "–¶–µ–ª–µ–≤—ã–µ",
            "IN.CONS.REDIR": "–¶–µ–ª–µ–≤—ã–µ",
            "IN.CONS.OWN": "–¶–µ–ª–µ–≤—ã–µ",
            "IN.CONS.THINK": "–¶–µ–ª–µ–≤—ã–µ",
            "IN.CONS.BUSY": "–¶–µ–ª–µ–≤—ã–µ",
            "IN.CONS.COST": "–¶–µ–ª–µ–≤—ã–µ",
            "IN.CONS.NODO": "–¶–µ–ª–µ–≤—ã–µ",
            "IN.CONS.CB": "–¶–µ–ª–µ–≤—ã–µ",
            "IN.CONS.OTHER": "–¶–µ–ª–µ–≤—ã–µ",
            "IN.BOOK": "–¶–µ–ª–µ–≤—ã–µ",
            "IN.FU.BOOK": "–¶–µ–ª–µ–≤—ã–µ",
            "IN.INFO.FU.NOBOOK": "–°–ø—Ä–∞–≤–æ—á–Ω—ã–µ",
            "OUT.NE": "–ù–µ —Ü–µ–ª–µ–≤—ã–µ",
            "OUT.CONS.MSG": "–¶–µ–ª–µ–≤—ã–µ",
            "OUT.CONS.REDIR": "–¶–µ–ª–µ–≤—ã–µ",
            "OUT.CONS.OWN": "–¶–µ–ª–µ–≤—ã–µ",
            "OUT.CONS.THINK": "–¶–µ–ª–µ–≤—ã–µ",
            "OUT.CONS.BUSY": "–¶–µ–ª–µ–≤—ã–µ",
            "OUT.CONS.COST": "–¶–µ–ª–µ–≤—ã–µ",
            "OUT.CONS.NODO": "–¶–µ–ª–µ–≤—ã–µ",
            "OUT.CONS.CB": "–¶–µ–ª–µ–≤—ã–µ",
            "OUT.CONS.OTHER": "–¶–µ–ª–µ–≤—ã–µ",
            "OUT.BOOK": "–¶–µ–ª–µ–≤—ã–µ",
            "OUT.FU.BOOK": "–¶–µ–ª–µ–≤—ã–µ",
            "OUT.INFO.FU.NOBOOK": "–°–ø—Ä–∞–≤–æ—á–Ω—ã–µ",
            "OUT.OBZ.BOOK": "–û–±–∑–≤–æ–Ω",
            "OUT.OBZ.NOBOOK": "–û–±–∑–≤–æ–Ω"
        }
        
        # –°–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç –±—É–¥–µ—Ç –≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å—Å—è –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–∏ –∏–∑ –ø—Ä–∞–≤–∏–ª

        # –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–π —à–∞–±–ª–æ–Ω –∏–º–µ–Ω–∏ —Ñ–∞–π–ª–∞ (—Ä–µ–≥—É–ª—è—Ä–Ω–æ–µ –≤—ã—Ä–∞–∂–µ–Ω–∏–µ)
        # –ï—Å–ª–∏ –≤–∫–ª—é—á–µ–Ω –≤ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞—Ö, –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –ø–µ—Ä–µ–¥ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–º–∏ —à–∞–±–ª–æ–Ω–∞–º–∏
        self.custom_filename_pattern = None
        self.custom_pattern_enabled = False
        self.custom_filename_patterns = []
        try:
            pattern_str = self.rules_manager.get_setting('filename_pattern_custom', '') or ''
            enabled = self.rules_manager.get_setting('filename_pattern_custom_enabled', '0') == '1'
            patterns_json = self.rules_manager.get_setting('filename_patterns_json', '') or ''
            if patterns_json:
                loaded_patterns = json.loads(patterns_json)
                if isinstance(loaded_patterns, list):
                    self.custom_filename_patterns = loaded_patterns
            if pattern_str and enabled:
                self.custom_filename_pattern = re.compile(pattern_str)
                self.custom_pattern_enabled = True
        except Exception:
            self.custom_filename_pattern = None
            self.custom_pattern_enabled = False
            self.custom_filename_patterns = []

    def _extract_with_custom_pattern(self, filename):
        """–ü—ã—Ç–∞–µ—Ç—Å—è —Ä–∞–∑–æ–±—Ä–∞—Ç—å –∏–º—è —Ñ–∞–π–ª–∞ –ø–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–º –ø–∞—Ç—Ç–µ—Ä–Ω–∞–º –∏–∑ –õ–ö."""
        if not getattr(self, 'custom_pattern_enabled', False):
            return None

        for pattern_cfg in self.custom_filename_patterns:
            try:
                regex = str((pattern_cfg or {}).get('regex') or '').strip()
                if not regex:
                    continue
                match = re.search(regex, filename)
                if not match:
                    continue

                phone_group = int((pattern_cfg or {}).get('phone_group') or 1)
                station_group = int((pattern_cfg or {}).get('station_group') or 2)
                date_group = int((pattern_cfg or {}).get('date_group') or 3)
                time_group = int((pattern_cfg or {}).get('time_group') or 4)
                datetime_group = (pattern_cfg or {}).get('datetime_group')
                datetime_format = str((pattern_cfg or {}).get('datetime_format') or '').strip()
                direction = str((pattern_cfg or {}).get('direction') or 'auto').strip().lower()

                phone_number = match.group(phone_group)
                station_number = match.group(station_group)
                call_date = "–ù–µ —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω–∞"
                call_time = "–ù–µ —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω–æ"

                if datetime_group:
                    datetime_value = match.group(int(datetime_group))
                    if datetime_format:
                        dt = datetime.strptime(datetime_value, datetime_format)
                        call_date = dt.strftime('%d.%m.%Y')
                        call_time = dt.strftime('%H:%M')
                    else:
                        call_date = datetime_value
                else:
                    date_str = match.group(date_group)
                    time_str = match.group(time_group)
                    try:
                        date_obj = datetime.strptime(date_str, '%Y-%m-%d')
                        call_date = date_obj.strftime('%d.%m.%Y')
                    except Exception:
                        call_date = date_str
                    try:
                        time_obj = datetime.strptime(time_str, '%H-%M-%S')
                        call_time = time_obj.strftime('%H:%M')
                    except Exception:
                        call_time = time_str

                if direction == 'incoming':
                    call_type = "–í—Ö–æ–¥—è—â–∏–π"
                elif direction == 'outgoing':
                    call_type = "–ò—Å—Ö–æ–¥—è—â–∏–π"
                else:
                    if len(str(phone_number)) >= 10 and 3 <= len(str(station_number)) <= 5:
                        call_type = "–ò—Å—Ö–æ–¥—è—â–∏–π"
                    elif len(str(station_number)) >= 10 and 3 <= len(str(phone_number)) <= 5:
                        call_type = "–í—Ö–æ–¥—è—â–∏–π"
                    else:
                        call_type = "–ù–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω"

                station_name = self.STATION_CODES.get(station_number, f"–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è —Å—Ç–∞–Ω—Ü–∏—è ({station_number})")
                return phone_number, call_date, call_time, station_number, station_name, call_type
            except Exception:
                continue

        return None

    def extract_file_info(self, filename):
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –Ω–æ–º–µ—Ä–∞ —Ç–µ–ª–µ—Ñ–æ–Ω–∞, –¥–∞—Ç—ã, –≤—Ä–µ–º–µ–Ω–∏, –Ω–æ–º–µ—Ä–∞ —Å—Ç–∞–Ω—Ü–∏–∏ –∏ —Ç–∏–ø–∞ –∑–≤–æ–Ω–∫–∞ –∏–∑ –∏–º–µ–Ω–∏ —Ñ–∞–π–ª–∞"""
        station_number = "–ù–µ —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω"
        phone_number = "–ù–µ —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω"
        call_date = "–ù–µ —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω–∞"
        call_time = "–ù–µ —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω–æ"
        call_type = "–ù–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω"

        parsed_custom = self._extract_with_custom_pattern(filename)
        if parsed_custom:
            return parsed_custom

        # 1. –°–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–±—É–µ–º –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–π —à–∞–±–ª–æ–Ω, –µ—Å–ª–∏ –æ–Ω –≤–∫–ª—é—á–µ–Ω.
        #    –û–∂–∏–¥–∞–µ—Ç—Å—è, —á—Ç–æ –≥—Ä—É–ø–ø—ã 1-4 —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—Ç: —Ç–µ–ª–µ—Ñ–æ–Ω, —Å—Ç–∞–Ω—Ü–∏—è, –¥–∞—Ç–∞, –≤—Ä–µ–º—è.
        if getattr(self, 'custom_pattern_enabled', False) and self.custom_filename_pattern:
            try:
                match = self.custom_filename_pattern.search(filename)
            except re.error:
                match = None
            if match:
                try:
                    phone_number = match.group(1)
                    station_number = match.group(2)
                    date_str = match.group(3)
                    time_str = match.group(4)
                    
                    try:
                        date_obj = datetime.strptime(date_str, '%Y-%m-%d')
                        call_date = date_obj.strftime('%d.%m.%Y')
                    except Exception:
                        call_date = date_str
                    
                    try:
                        time_obj = datetime.strptime(time_str, '%H-%M-%S')
                        call_time = time_obj.strftime('%H:%M')
                    except Exception:
                        call_time = time_str
                    
                    station_name = self.STATION_CODES.get(station_number, f"–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è —Å—Ç–∞–Ω—Ü–∏—è ({station_number})")
                    return phone_number, call_date, call_time, station_number, station_name, call_type
                except Exception:
                    # –ü—Ä–∏ –ª—é–±–æ–π –æ—à–∏–±–∫–µ –ø–∞–¥–∞–µ–º –æ–±—Ä–∞—Ç–Ω–æ –Ω–∞ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—É—é –ª–æ–≥–∏–∫—É
                    phone_number = "–ù–µ —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω"
                    station_number = "–ù–µ —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω"
                    call_date = "–ù–µ —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω–∞"
                    call_time = "–ù–µ —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω–æ"
                    call_type = "–ù–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω"

        # 2. –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–µ —à–∞–±–ª–æ–Ω—ã –¥–ª—è –∏–∑–≤–µ—Å—Ç–Ω—ã—Ö —Ñ–æ—Ä–º–∞—Ç–æ–≤ —Ñ–∞–π–ª–æ–≤
        patterns = [
            # –ù–æ–≤—ã–π —Ñ–æ—Ä–º–∞—Ç –±–µ–∑ –ø—Ä–µ—Ñ–∏–∫—Å–∞ fs_, –≤–∞—Ä–∏–∞–Ω—Ç—ã:
            # 1) –ò—Å—Ö–æ–¥—è—â–∏–µ: —Ç–µ–ª–µ—Ñ–æ–Ω_—Å—Ç–∞–Ω—Ü–∏—è_–¥–∞—Ç–∞-–≤—Ä–µ–º—è
            #    09278612779_401_2025-12-12-14-20-02.txt
            # 2) –í—Ö–æ–¥—è—â–∏–µ: —Å—Ç–∞–Ω—Ü–∏—è_—Ç–µ–ª–µ—Ñ–æ–Ω_–¥–∞—Ç–∞-–≤—Ä–µ–º—è
            #    401_79613420826_2026-01-20-11-02-25.txt
            r'(\d{10,11})_(\d{3,5})_(\d{4}-\d{2}-\d{2})-(\d{2}-\d{2}-\d{2})',
            r'(\d{3,5})_(\d{10,11})_(\d{4}-\d{2}-\d{2})-(\d{2}-\d{2}-\d{2})',
            # –°—Ç–∞—Ä—ã–µ —Ñ–æ—Ä–º–∞—Ç—ã —Å –ø—Ä–µ—Ñ–∏–∫—Å–æ–º fs_
            r'fs_(\d{11})_(\d{4})_(\d{4}-\d{2}-\d{2})-(\d{2}-\d{2}-\d{2})',  # –í—Ö–æ–¥—è—â–∏–π: fs_79084901148_9327_2025-09-25-10-11-07
            r'fs_(\d{4})_(\d{11})_(\d{4}-\d{2}-\d{2})-(\d{2}-\d{2}-\d{2})',  # –ò—Å—Ö–æ–¥—è—â–∏–π: fs_9307_79872960287_2025-09-25-09-47-23
            r'(\d{10,11})_(\d{4})_(\d{4}-\d{2}-\d{2})-(\d{2}-\d{2}-\d{2})',
            r'.*?(\d{10,11}).*?(\d{3,5}).*?(\d{4}-\d{2}-\d{2})-(\d{2}-\d{2}-\d{2})'
        ]
        
        for pattern in patterns:
            match = re.search(pattern, filename)
            if match:
                if pattern.startswith(r'(\d{10,11})_(\d{3,5})_'):
                    # –ò—Å—Ö–æ–¥—è—â–∏–π –∑–≤–æ–Ω–æ–∫: —Ç–µ–ª–µ—Ñ–æ–Ω_—Å—Ç–∞–Ω—Ü–∏—è_–¥–∞—Ç–∞-–≤—Ä–µ–º—è
                    phone_number = match.group(1)
                    station_number = match.group(2)
                    call_type = "–ò—Å—Ö–æ–¥—è—â–∏–π"
                elif pattern.startswith(r'(\d{3,5})_(\d{10,11})_'):
                    # –í—Ö–æ–¥—è—â–∏–π –∑–≤–æ–Ω–æ–∫: —Å—Ç–∞–Ω—Ü–∏—è_—Ç–µ–ª–µ—Ñ–æ–Ω_–¥–∞—Ç–∞-–≤—Ä–µ–º—è
                    station_number = match.group(1)
                    phone_number = match.group(2)
                    call_type = "–í—Ö–æ–¥—è—â–∏–π"
                elif r'fs_(\d{11})_(\d{4})_' in pattern:
                    # –í—Ö–æ–¥—è—â–∏–π –∑–≤–æ–Ω–æ–∫: fs_79084901148_9327_2025-09-25-10-11-07
                    phone_number = match.group(1)
                    station_number = match.group(2)
                    call_type = "–í—Ö–æ–¥—è—â–∏–π"
                elif r'fs_(\d{4})_(\d{11})_' in pattern:
                    # –ò—Å—Ö–æ–¥—è—â–∏–π –∑–≤–æ–Ω–æ–∫: fs_9307_79872960287_2025-09-25-09-47-23
                    station_number = match.group(1)
                    phone_number = match.group(2)
                    call_type = "–ò—Å—Ö–æ–¥—è—â–∏–π"
                else:
                    # –î—Ä—É–≥–∏–µ —Ñ–æ—Ä–º–∞—Ç—ã - –æ–ø—Ä–µ–¥–µ–ª—è–µ–º –ø–æ –¥–ª–∏–Ω–µ –≥—Ä—É–ø–ø:
                    # –æ–¥–Ω–∞ –≥—Ä—É–ø–ø–∞ 10‚Äì11 —Ü–∏—Ñ—Ä (—Ç–µ–ª–µ—Ñ–æ–Ω), –¥—Ä—É–≥–∞—è 3‚Äì5 —Ü–∏—Ñ—Ä (—Å—Ç–∞–Ω—Ü–∏—è)
                    g1 = match.group(1)
                    g2 = match.group(2)
                    if len(g1) >= 10 and 3 <= len(g2) <= 5:
                        phone_number = g1
                        station_number = g2
                    elif len(g2) >= 10 and 3 <= len(g1) <= 5:
                        station_number = g1
                        phone_number = g2
                    else:
                        phone_number = g1
                        station_number = g2
                    call_type = "–ù–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω"
                
                date_str = match.group(3)
                time_str = match.group(4)
                
                try:
                    date_obj = datetime.strptime(date_str, '%Y-%m-%d')
                    call_date = date_obj.strftime('%d.%m.%Y')
                except:
                    call_date = date_str
                
                try:
                    time_obj = datetime.strptime(time_str, '%H-%M-%S')
                    call_time = time_obj.strftime('%H:%M')
                except:
                    call_time = time_str
                
                break
        
        station_name = self.STATION_CODES.get(station_number, f"–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è —Å—Ç–∞–Ω—Ü–∏—è ({station_number})")
        
        return phone_number, call_date, call_time, station_number, station_name, call_type

    def convert_legacy_to_new_category(self, legacy_category, call_type):
        """–ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ —Å—Ç–∞—Ä–æ–π –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ –≤ –Ω–æ–≤—É—é —Å —É—á–µ—Ç–æ–º —Ç–∏–ø–∞ –∑–≤–æ–Ω–∫–∞"""
        if call_type == "–í—Ö–æ–¥—è—â–∏–π":
            # –î–ª—è –≤—Ö–æ–¥—è—â–∏—Ö –∑–≤–æ–Ω–∫–æ–≤ –∏—Å–ø–æ–ª—å–∑—É–µ–º –ø—Ä—è–º–æ–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ
            return self.LEGACY_TO_NEW_MAPPING.get(legacy_category, "1")
        elif call_type == "–ò—Å—Ö–æ–¥—è—â–∏–π":
            # –î–ª—è –∏—Å—Ö–æ–¥—è—â–∏—Ö –∑–≤–æ–Ω–∫–æ–≤ –¥–æ–±–∞–≤–ª—è–µ–º 13 –∫ –Ω–æ–º–µ—Ä—É –∫–∞—Ç–µ–≥–æ—Ä–∏–∏
            incoming_category = self.LEGACY_TO_NEW_MAPPING.get(legacy_category, "1")
            incoming_num = int(incoming_category)
            outgoing_num = incoming_num + 13
            return str(outgoing_num)
        else:
            # –î–ª—è –Ω–µ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω—ã—Ö —Ç–∏–ø–æ–≤ –∏—Å–ø–æ–ª—å–∑—É–µ–º –≤—Ö–æ–¥—è—â–∏–µ
            return self.LEGACY_TO_NEW_MAPPING.get(legacy_category, "1")

    def get_category_name(self, category_num):
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –Ω–∞–∑–≤–∞–Ω–∏—è –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ –ø–æ –Ω–æ–º–µ—Ä—É"""
        return self.NEW_CATEGORIES.get(category_num, "–ù–ï–ò–ó–í–ï–°–¢–ù–ê–Ø –ö–ê–¢–ï–ì–û–†–ò–Ø")

    def get_category_group(self, category_name):
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –≥—Ä—É–ø–ø—ã –∫–∞—Ç–µ–≥–æ—Ä–∏–∏"""
        return self.CATEGORY_GROUPS.get(category_name, "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ")

    def build_call_history_context(self, phone_number, current_filename, processed_calls):
        """–ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –ø—Ä–µ–¥—ã–¥—É—â–∏—Ö –∑–≤–æ–Ω–∫–æ–≤ –∫–ª–∏–µ–Ω—Ç–∞"""
        if not phone_number or phone_number == "–ù–µ —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω":
            return "–ö–û–ù–¢–ï–ö–°–¢: –ü–µ—Ä–≤—ã–π –∑–≤–æ–Ω–æ–∫ –∫–ª–∏–µ–Ω—Ç–∞ –∏–ª–∏ –Ω–æ–º–µ—Ä –Ω–µ —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω."

        client_calls = []
        for call in processed_calls:
            if call['–ù–æ–º–µ—Ä —Ç–µ–ª–µ—Ñ–æ–Ω–∞'] == phone_number and call['–§–∞–π–ª'] != current_filename:
                client_calls.append(call)

        if not client_calls:
            return f"–ö–û–ù–¢–ï–ö–°–¢: –ü–µ—Ä–≤—ã–π –∑–≤–æ–Ω–æ–∫ –∫–ª–∏–µ–Ω—Ç–∞ {phone_number}."

        client_calls.sort(key=lambda x: (x['–î–∞—Ç–∞'], x['–í—Ä–µ–º—è']))

        history_text = f"–ö–û–ù–¢–ï–ö–°–¢: –ò—Å—Ç–æ—Ä–∏—è –∑–≤–æ–Ω–∫–æ–≤ –∫–ª–∏–µ–Ω—Ç–∞ {phone_number} ({len(client_calls)} –ø—Ä–µ–¥—ã–¥—É—â–∏—Ö –∑–≤–æ–Ω–∫–æ–≤):\n"

        for i, call in enumerate(client_calls[-5:], 1):
            history_text += f"{i}. {call['–î–∞—Ç–∞']} {call['–í—Ä–µ–º—è']} - {call['–ö–∞—Ç–µ–≥–æ—Ä–∏—è']} ({call['–†–µ–∑—É–ª—å—Ç–∞—Ç']})\n"
            history_text += f"   –û–±–æ—Å–Ω–æ–≤–∞–Ω–∏–µ: {call['–û–±–æ—Å–Ω–æ–≤–∞–Ω–∏–µ'][:100]}...\n"

        categories = [call['–†–µ–∑—É–ª—å—Ç–∞—Ç'] for call in client_calls]

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∑–∞–ø–∏—Å–∏ (–Ω–æ–≤—ã–µ —Å–∏–º–≤–æ–ª—å–Ω—ã–µ –∫–æ–¥—ã)
        record_categories = ['IN.BOOK', 'OUT.BOOK', 'IN.FU.BOOK', 'OUT.FU.BOOK', '2', '15']
        has_records = any(cat in record_categories for cat in categories)
        if has_records:
            # –ò—â–µ–º –ø–æ—Å–ª–µ–¥–Ω—é—é –∑–∞–ø–∏—Å—å
            for call in reversed(client_calls):
                if call['–†–µ–∑—É–ª—å—Ç–∞—Ç'] in record_categories:
                    history_text += f"\n‚ö†Ô∏è –ö–õ–ò–ï–ù–¢ –£–ñ–ï –ó–ê–ü–ò–°–ê–ù: {call['–î–∞—Ç–∞']} {call['–í—Ä–µ–º—è']} –≤ {call['–°—Ç–∞–Ω—Ü–∏—è']}\n"
                    break

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∑–∞–ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –ø–µ—Ä–µ–∑–≤–æ–Ω—ã (–Ω–æ–≤—ã–µ —Å–∏–º–≤–æ–ª—å–Ω—ã–µ –∫–æ–¥—ã)
        callback_categories = ['IN.CONS.CB', 'OUT.CONS.CB', '10', '23']
        if any(cat in callback_categories for cat in categories):
            history_text += "–ò–°–¢–û–†–ò–Ø: –ë—ã–ª–∏ –∑–∞–ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –ø–µ—Ä–µ–∑–≤–æ–Ω—ã\n"

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –º–Ω–æ–≥–æ–∫—Ä–∞—Ç–Ω—ã–µ –æ—Ç–∫–∞–∑—ã/—Ä–∞–∑–º—ã—à–ª–µ–Ω–∏—è (–Ω–æ–≤—ã–µ —Å–∏–º–≤–æ–ª—å–Ω—ã–µ –∫–æ–¥—ã)
        think_categories = ['IN.CONS.THINK', 'OUT.CONS.THINK', '4', '17']
        think_count = sum(1 for cat in categories if cat in think_categories)
        if think_count > 1:
            history_text += "–ò–°–¢–û–†–ò–Ø: –ú–Ω–æ–≥–æ–∫—Ä–∞—Ç–Ω—ã–µ –æ—Ç–∫–∞–∑—ã/—Ä–∞–∑–º—ã—à–ª–µ–Ω–∏—è –∫–ª–∏–µ–Ω—Ç–∞\n"

        return history_text

    def build_training_examples_context(self, transcription):
        """–ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ —Å –æ–±—É—á–∞—é—â–∏–º–∏ –ø—Ä–∏–º–µ—Ä–∞–º–∏"""
        similar_examples = self.training_manager.get_similar_examples(transcription, limit=3)
        
        if not similar_examples:
            return "–û–ë–£–ß–ê–Æ–©–ò–ï –ü–†–ò–ú–ï–†–´: –ù–µ—Ç –ø–æ—Ö–æ–∂–∏—Ö –ø—Ä–∏–º–µ—Ä–æ–≤ –≤ –±–∞–∑–µ."
        
        examples_text = "–û–ë–£–ß–ê–Æ–©–ò–ï –ü–†–ò–ú–ï–†–´ (–∏–∑—É—á–∏ –ø–∞—Ç—Ç–µ—Ä–Ω—ã):\n"
        for i, example in enumerate(similar_examples, 1):
            examples_text += f"{i}. –ö–∞—Ç–µ–≥–æ—Ä–∏—è {example['category']}: {self.get_category_description(example['category'])}\n"
            examples_text += f"   –¢—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è: {example['transcription'][:150]}...\n"
            examples_text += f"   –û–±–æ—Å–Ω–æ–≤–∞–Ω–∏–µ: {example['reasoning'][:150]}...\n\n"
        
        return examples_text

    def get_category_description(self, category_num):
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –æ–ø–∏—Å–∞–Ω–∏—è –∫–∞—Ç–µ–≥–æ—Ä–∏–∏"""
        return self.NEW_CATEGORIES.get(category_num, "–ù–ï–ò–ó–í–ï–°–¢–ù–ê–Ø –ö–ê–¢–ï–ì–û–†–ò–Ø")

    def _resolve_chat_completions_url(self):
        url = str(self.base_url or "").strip()
        if not url:
            return "https://api.deepseek.com/v1/chat/completions"
        lower_url = url.lower().rstrip("/")
        if lower_url.endswith("/chat/completions"):
            return url
        if lower_url.endswith("/v1"):
            return f"{url.rstrip('/')}/chat/completions"
        return url

    def _append_debug_log(self, event, payload):
        try:
            entry = {
                "ts": datetime.now().isoformat(timespec="seconds"),
                "event": str(event),
                "payload": payload or {},
            }
            self.debug_log_path.parent.mkdir(parents=True, exist_ok=True)
            with self.debug_log_path.open("a", encoding="utf-8") as f:
                f.write(json.dumps(entry, ensure_ascii=False) + "\n")
        except Exception:
            pass

    def _request_llm_with_retries(self, payload, max_retries=3, delay=5):
        url = self._resolve_chat_completions_url()
        headers = {
            "Authorization": f"Bearer {self.api_key}",
            "Content-Type": "application/json",
        }
        last_error = ""
        for attempt in range(max_retries):
            try:
                resp = requests.post(url, headers=headers, json=payload, timeout=90)
                if resp.status_code == 200:
                    self._append_debug_log(
                        "llm_http_ok",
                        {"url": url, "attempt": attempt + 1, "status_code": resp.status_code},
                    )
                    return resp
                last_error = f"HTTP {resp.status_code}: {resp.text[:500]}"
                self._append_debug_log(
                    "llm_http_error",
                    {
                        "url": url,
                        "attempt": attempt + 1,
                        "status_code": resp.status_code,
                        "body_preview": (resp.text or "")[:1200],
                    },
                )
            except Exception as exc:
                last_error = str(exc)
                self._append_debug_log(
                    "llm_request_exception",
                    {"url": url, "attempt": attempt + 1, "error": str(exc)},
                )
            if attempt < max_retries - 1:
                time.sleep(delay)
        raise RuntimeError(last_error or "LLM request failed")

    def _clean_llm_text(self, text):
        cleaned = str(text or "").strip()
        if cleaned.startswith("```"):
            cleaned = re.sub(r"^```[a-zA-Z0-9_-]*\s*", "", cleaned)
            cleaned = re.sub(r"\s*```$", "", cleaned).strip()
        return cleaned

    def _extract_category_from_text(self, text):
        if not text:
            return None
        # –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç: –∫–æ–¥—ã –Ω–æ–≤–æ–π —Å—Ö–µ–º—ã, –µ—Å–ª–∏ –≤—Å—Ç—Ä–µ—Ç–∏–ª–∏—Å—å –≤ –ª—é–±–æ–º –º–µ—Å—Ç–µ –æ—Ç–≤–µ—Ç–∞.
        keys = sorted(self.NEW_CATEGORIES.keys(), key=len, reverse=True)
        for code in keys:
            if re.search(rf"(?<![A-Z0-9_.]){re.escape(code)}(?![A-Z0-9_.])", text):
                return code
        return None

    def _parse_llm_result(self, raw_text, call_type):
        text = self._clean_llm_text(raw_text)
        if not text:
            return None, None

        # –§–æ—Ä–º–∞—Ç 1: CODE|reasoning
        if "|" in text:
            left, right = text.split("|", 1)
            cat = self._extract_category_from_text(left.strip()) or left.strip()
            if cat in self.NEW_CATEGORIES:
                return cat, right.strip() or text

        # –§–æ—Ä–º–∞—Ç 2: JSON
        try:
            parsed = json.loads(text)
            if isinstance(parsed, dict):
                cat_raw = (
                    parsed.get("category")
                    or parsed.get("result")
                    or parsed.get("code")
                    or parsed.get("category_num")
                    or ""
                )
                reasoning = (
                    parsed.get("reasoning")
                    or parsed.get("analysis")
                    or parsed.get("explanation")
                    or parsed.get("comment")
                    or ""
                )
                cat = self._extract_category_from_text(str(cat_raw))
                if cat in self.NEW_CATEGORIES:
                    return cat, str(reasoning or text).strip()
        except Exception:
            pass

        # –§–æ—Ä–º–∞—Ç 3: "–ö–∞—Ç–µ–≥–æ—Ä–∏—è: CODE" –∏ "–û–±–æ—Å–Ω–æ–≤–∞–Ω–∏–µ: ..."
        cat_match = re.search(r"(?:–∫–∞—Ç–µ–≥–æ—Ä–∏[—è–∏]|category|result|–∫–æ–¥)\s*[:\-]\s*([A-Z][A-Z0-9_.]+)", text, re.IGNORECASE)
        if cat_match:
            cat = self._extract_category_from_text(cat_match.group(1))
            if cat in self.NEW_CATEGORIES:
                return cat, text

        # –§–æ—Ä–º–∞—Ç 4: –∫–æ–¥ –≥–¥–µ-—Ç–æ –≤ —Ç–µ–∫—Å—Ç–µ
        cat = self._extract_category_from_text(text)
        if cat in self.NEW_CATEGORIES:
            return cat, text

        # –§–æ–ª–±—ç–∫: –Ω–µ —Ä–æ–Ω—è–µ–º –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—é –Ω–∞ "—Ñ–æ—Ä–º–∞—Ç–µ", –≤—ã–±–∏—Ä–∞–µ–º –±–µ–∑–æ–ø–∞—Å–Ω—É—é –∫–∞—Ç–µ–≥–æ—Ä–∏—é.
        fallback_cat = "IN.CONS.OTHER" if str(call_type).startswith("–í—Ö–æ–¥") else "OUT.CONS.OTHER"
        return fallback_cat, f"{text}\n\n[auto_fallback: —Ñ–æ—Ä–º–∞—Ç –æ—Ç–≤–µ—Ç–∞ –Ω–µ —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω]"

    def classify_call_with_reasoning(self, transcription, call_history_context="", training_examples_context="", call_type="–ù–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω"):
        """–ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –∑–≤–æ–Ω–∫–∞ —Å –ø–æ–ª—É—á–µ–Ω–∏–µ–º –æ–±–æ—Å–Ω–æ–≤–∞–Ω–∏—è, —É—á–µ—Ç–æ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –∏ –æ–±—É—á–∞—é—â–∏—Ö –ø—Ä–∏–º–µ—Ä–æ–≤"""
        try:
            # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —Å–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç –∏–∑ –∞–∫—Ç—É–∞–ª—å–Ω—ã—Ö –ø—Ä–∞–≤–∏–ª
            system_prompt = self.rules_manager.generate_system_prompt(
                call_history_context, 
                training_examples_context,
                call_type
            )

            payload = {
                "model": self.model,
                "messages": [
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": transcription},
                ],
                "temperature": 0.1,
                "max_tokens": 800,
            }
            transcript_hash = hashlib.md5((transcription or "").encode("utf-8")).hexdigest()
            self._append_debug_log(
                "llm_request",
                {
                    "url": self._resolve_chat_completions_url(),
                    "model": self.model,
                    "call_type": call_type,
                    "transcript_hash": transcript_hash,
                    "transcript_preview": (transcription or "")[:800],
                    "system_prompt_preview": (system_prompt or "")[:1000],
                },
            )
            response = self._request_llm_with_retries(payload, max_retries=3, delay=10)
            data = response.json()
            result = (
                data.get("choices", [{}])[0]
                .get("message", {})
                .get("content", "")
            ).strip()
            self._append_debug_log(
                "llm_response",
                {
                    "transcript_hash": transcript_hash,
                    "response_preview": (result or "")[:2000],
                },
            )
            if not result:
                return "–û—à–∏–±–∫–∞", "–ü—É—Å—Ç–æ–π –æ—Ç–≤–µ—Ç –æ—Ç LLM"

            category_num, reasoning = self._parse_llm_result(result, call_type)
            self._append_debug_log(
                "llm_parsed",
                {
                    "transcript_hash": transcript_hash,
                    "parsed_category": category_num,
                    "reasoning_preview": (reasoning or "")[:800],
                },
            )
            if category_num in self.NEW_CATEGORIES:
                return category_num, reasoning
            return "–û—à–∏–±–∫–∞", "–ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç –æ—Ç–≤–µ—Ç–∞"

        except Exception as e:
            self._append_debug_log("llm_classification_exception", {"error": str(e)})
            return "–û—à–∏–±–∫–∞", f"API –æ—à–∏–±–∫–∞: {str(e)}"


    def validate_classification_with_context(self, category_num, phone_number, current_filename, processed_calls, transcription, reasoning=""):
        """–†–∞—Å—à–∏—Ä–µ–Ω–Ω–∞—è –≤–∞–ª–∏–¥–∞—Ü–∏—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ —Å —É—á–µ—Ç–æ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –∏ –æ–±—É—á–∞—é—â–∏—Ö –ø—Ä–∏–º–µ—Ä–æ–≤"""

        # –ü–†–ò–û–†–ò–¢–ï–¢–ù–û–ï –ü–†–ê–í–ò–õ–û 0: –õ–Æ–ë–û–ô –ø–æ–≤—Ç–æ—Ä–Ω—ã–π –∑–≤–æ–Ω–æ–∫ –û–ë–Ø–ó–ê–¢–ï–õ–¨–ù–û –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –ø–æ—Å–ª–µ–¥—É—é—â–∏–º –∫–æ–Ω—Ç–∞–∫—Ç–æ–º
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –∏—Å—Ç–æ—Ä–∏–∏ –∑–≤–æ–Ω–∫–æ–≤ –æ—Ç —ç—Ç–æ–≥–æ –∫–ª–∏–µ–Ω—Ç–∞
        client_previous_calls = [call for call in processed_calls
                                if call['–ù–æ–º–µ—Ä —Ç–µ–ª–µ—Ñ–æ–Ω–∞'] == phone_number and call['–§–∞–π–ª'] != current_filename]
        
        if client_previous_calls and phone_number and phone_number != "–ù–µ —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω":
            # –ï—Å–ª–∏ –µ—Å—Ç—å –∏—Å—Ç–æ—Ä–∏—è - –ø—Ä–æ–≤–µ—Ä—è–µ–º, –Ω—É–∂–Ω–æ –ª–∏ –ø–µ—Ä–µ–∫–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞—Ç—å
            # –ù–ï –ø–µ—Ä–µ–∫–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä—É–µ–º, –µ—Å–ª–∏ —ç—Ç–æ —É–∂–µ –ø—Ä–∞–≤–∏–ª—å–Ω—ã–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ –ø–æ—Å–ª–µ–¥—É—é—â–µ–≥–æ –∫–æ–Ω—Ç–∞–∫—Ç–∞ –∏–ª–∏ –Ω–µ —Ü–µ–ª–µ–≤–æ–π
            if category_num not in ['IN.FU.BOOK', 'OUT.FU.BOOK', 'IN.INFO.FU.NOBOOK', 'OUT.INFO.FU.NOBOOK', 'IN.NE', 'OUT.NE']:
                # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –∏–∑ —Ç–µ–∫—É—â–µ–π –∫–∞—Ç–µ–≥–æ—Ä–∏–∏
                direction_prefix = 'IN.' if category_num.startswith('IN.') or (category_num.isdigit() and int(category_num) <= 13) else 'OUT.'
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –±—ã–ª–∞ –ª–∏ –ó–ê–ü–ò–°–¨ –≤ –∏—Å—Ç–æ—Ä–∏–∏ (–∫–ª–∏–µ–Ω—Ç —É–∂–µ –∑–∞–ø–∏—Å–∞–Ω)
                has_previous_record = any(
                    call.get('–†–µ–∑—É–ª—å—Ç–∞—Ç') in ['IN.BOOK', 'OUT.BOOK', 'IN.FU.BOOK', 'OUT.FU.BOOK', '2', '15'] 
                    for call in client_previous_calls
                )
                
                # –ï—Å–ª–∏ AI –∫–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–ª –∫–∞–∫ –Ω–æ–≤—É—é –∑–∞–ø–∏—Å—å (BOOK)
                if category_num in ['IN.BOOK', 'OUT.BOOK']:
                    if has_previous_record:
                        # –ö–ª–∏–µ–Ω—Ç –£–ñ–ï –ó–ê–ü–ò–°–ê–ù - —ç—Ç–æ –Ω–µ –Ω–æ–≤–∞—è –∑–∞–ø–∏—Å—å, –∞ –ø–æ—Å–ª–µ–¥—É—é—â–∏–π –∫–æ–Ω—Ç–∞–∫—Ç –ë–ï–ó –∑–∞–ø–∏—Å–∏
                        correct_category = f'{direction_prefix}INFO.FU.NOBOOK'
                        return correct_category, f'–ü–û–í–¢–û–†–ù–´–ô –ó–í–û–ù–û–ö: –∫–ª–∏–µ–Ω—Ç —É–∂–µ –∑–∞–ø–∏—Å–∞–Ω - –ø–µ—Ä–µ–∫–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–æ –∏–∑ {category_num}'
                    else:
                        # –ö–ª–∏–µ–Ω—Ç –Ω–µ –∑–∞–ø–∏—Å–∞–Ω, –Ω–æ –∑–≤–æ–Ω–∏—Ç –Ω–µ –ø–µ—Ä–≤—ã–π —Ä–∞–∑ - –ø–æ—Å–ª–µ–¥—É—é—â–∏–π –∫–æ–Ω—Ç–∞–∫—Ç –° –ó–ê–ü–ò–°–¨–Æ
                        correct_category = f'{direction_prefix}FU.BOOK'
                        return correct_category, f'–ü–û–í–¢–û–†–ù–´–ô –ó–í–û–ù–û–ö: –Ω–æ–≤–∞—è –∑–∞–ø–∏—Å—å - –ø–µ—Ä–µ–∫–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–æ –∏–∑ {category_num}'
                
                # –ï—Å–ª–∏ AI –∫–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–ª –∫–∞–∫ –∫–æ–Ω—Å—É–ª—å—Ç–∞—Ü–∏—é –∏–ª–∏ –¥—Ä—É–≥–æ–µ
                else:
                    # –õ—é–±–∞—è –∫–æ–Ω—Å—É–ª—å—Ç–∞—Ü–∏—è/—É—Ç–æ—á–Ω–µ–Ω–∏–µ –ø—Ä–∏ –Ω–∞–ª–∏—á–∏–∏ –∏—Å—Ç–æ—Ä–∏–∏ - —ç—Ç–æ –ø–æ—Å–ª–µ–¥—É—é—â–∏–π –∫–æ–Ω—Ç–∞–∫—Ç –ë–ï–ó –∑–∞–ø–∏—Å–∏
                    correct_category = f'{direction_prefix}INFO.FU.NOBOOK'
                    return correct_category, f'–ü–û–í–¢–û–†–ù–´–ô –ó–í–û–ù–û–ö: –∫–æ–Ω—Å—É–ª—å—Ç–∞—Ü–∏—è - –ø–µ—Ä–µ–∫–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–æ –∏–∑ {category_num}'

        # –ü—Ä–∞–≤–∏–ª–æ 1: –ü–µ—Ä–≤—ã–π –∑–≤–æ–Ω–æ–∫ –Ω–µ –º–æ–∂–µ—Ç –±—ã—Ç—å "–ü–æ—Å–ª–µ–¥—É—é—â–∏–º –∫–æ–Ω—Ç–∞–∫—Ç–æ–º"
        if category_num in ['IN.FU.BOOK', 'OUT.FU.BOOK', 'IN.INFO.FU.NOBOOK', 'OUT.INFO.FU.NOBOOK']:
            if not client_previous_calls:
                return 'IN.CONS.OTHER' if category_num.startswith('IN.') else 'OUT.CONS.OTHER', '–ü–ï–†–í–´–ô –ó–í–û–ù–û–ö –ö–õ–ò–ï–ù–¢–ê - –ø–µ—Ä–µ–∫–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–æ –≤ "–ö–æ–Ω—Å—É–ª—å—Ç–∞—Ü–∏—è"'

        # –ü—Ä–∞–≤–∏–ª–æ 1.1: –ï—Å–ª–∏ –∫–ª–∏–µ–Ω—Ç –£–ñ–ï –ó–ê–ü–ò–°–ê–ù - –Ω–µ –º–æ–∂–µ—Ç –±—ã—Ç—å "–ü–æ—Å–ª–µ–¥—É—é—â–∏–π –∫–æ–Ω—Ç–∞–∫—Ç –° –ó–ê–ü–ò–°–¨–Æ"
        # –î–æ–ª–∂–µ–Ω –±—ã—Ç—å "–ü–æ—Å–ª–µ–¥—É—é—â–∏–π –∫–æ–Ω—Ç–∞–∫—Ç –ë–ï–ó –∑–∞–ø–∏—Å–∏"
        if category_num in ['IN.FU.BOOK', 'OUT.FU.BOOK']:
            client_previous_calls = [call for call in processed_calls
                                    if call['–ù–æ–º–µ—Ä —Ç–µ–ª–µ—Ñ–æ–Ω–∞'] == phone_number and call['–§–∞–π–ª'] != current_filename]

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ —É–∂–µ –∑–∞–ø–∏—Å—å —É –∫–ª–∏–µ–Ω—Ç–∞
            has_existing_record = any(call.get('–†–µ–∑—É–ª—å—Ç–∞—Ç') in ['IN.BOOK', 'OUT.BOOK', 'IN.FU.BOOK', 'OUT.FU.BOOK'] for call in client_previous_calls)
            
            if has_existing_record:
                return 'IN.INFO.FU.NOBOOK' if category_num.startswith('IN.') else 'OUT.INFO.FU.NOBOOK', '–ö–õ–ò–ï–ù–¢ –£–ñ–ï –ó–ê–ü–ò–°–ê–ù - –ø–µ—Ä–µ–∫–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–æ –≤ "–ü–æ—Å–ª–µ–¥—É—é—â–∏–π –∫–æ–Ω—Ç–∞–∫—Ç –ë–ï–ó –∑–∞–ø–∏—Å–∏"'

        # –ü—Ä–∞–≤–∏–ª–æ 2: –ü—Ä–æ–≤–µ—Ä–∫–∞ –ª–æ–∂–Ω–æ–π "–ó–∞–ø–∏—Å–∏ –Ω–∞ —Å–µ—Ä–≤–∏—Å"
        if category_num in ['IN.BOOK', 'OUT.BOOK', 'IN.FU.BOOK', 'OUT.FU.BOOK']:
            reasoning_lower = reasoning.lower() if reasoning else ""
            
            not_recorded_phrases = [
                "–ø–æ–¥—É–º–∞—é", "–Ω–∞–π–¥—É —Ä–µ—à–µ–Ω–∏–µ", "–ø–µ—Ä–µ–∑–≤–æ–Ω—é", "–µ—Å–ª–∏ –Ω–∞–¥—É–º–∞–µ—Ç",
                "—É–∂–µ –Ω–∞—à–µ–ª", "—Å–ø–∞—Å–∏–±–æ", "—É—Ç–æ—á–Ω–∏—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é",
                "–¥–æ–≥–æ–≤–æ—Ä–µ–Ω–Ω–æ—Å—Ç—å –æ –¥–∞–ª—å–Ω–µ–π—à–µ–º –∫–æ–Ω—Ç–∞–∫—Ç–µ", "–∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–π –∑–∞–ø–∏—Å–∏ –Ω–µ –±—ã–ª–æ",
                "–Ω–µ –ø—Ä–æ–∏—Å—Ö–æ–¥–∏—Ç", "–æ—Ç–ª–æ–∂–µ–Ω–æ", "–≤—Ä–µ–º—è –Ω–∞ —Ä–∞–∑–¥—É–º—å–µ"
            ]
            
            if any(phrase in reasoning_lower for phrase in not_recorded_phrases):
                return 'IN.CONS.OTHER' if category_num.startswith('IN.') else 'OUT.CONS.OTHER', '–ù–ï–¢ –ö–û–ù–ö–†–ï–¢–ù–û–ô –ó–ê–ü–ò–°–ò - –ø–µ—Ä–µ–∫–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–æ –≤ "–ö–æ–Ω—Å—É–ª—å—Ç–∞—Ü–∏—è"'
            
            subsequent_contact_phrases = [
                "—É–∂–µ –∑–∞–ø–∏—Å–∞–Ω", "–ø–æ–¥—Ç–≤–µ—Ä–∂–¥–∞–µ—Ç –∑–∞–ø–∏—Å—å", "—Å—É—â–µ—Å—Ç–≤—É—é—â–∞—è –∑–∞–ø–∏—Å—å",
                "–ø–µ—Ä–µ–Ω–æ—Å–∏—Ç –∑–∞–ø–∏—Å—å", "—É—Ç–æ—á–Ω—è–µ—Ç –¥–µ—Ç–∞–ª–∏ –∑–∞–ø–∏—Å–∏", "–∑–∞–≤—Ç—Ä–∞ –∂–¥–µ–º",
                "–ø–æ–≤—Ç–æ—Ä–Ω—ã–π –∫–æ–Ω—Ç–∞–∫—Ç –ø–æ —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É—é—â–µ–π –∑–∞–ø–∏—Å–∏", "–ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏–µ –∑–∞–ø–∏—Å–∏",
                "–∑–≤–æ–Ω–∏–ª–∏ –≤–æ—Ç —Å–µ–π—á–∞—Å –Ω–∞ —Å–µ–≥–æ–¥–Ω—è –∑–∞–ø–∏—Å–∞–Ω–Ω–æ–≥–æ", "–≤–∞—Å –∂–¥–µ–º", "–º–∞—à–∏–Ω–∞ –≤ —Å–µ—Ä–≤–∏—Å–µ",
                "–º–∞—à–∏–Ω–∞ –Ω–∞ —Ä–µ–º–æ–Ω—Ç–µ", "–∞–≤—Ç–æ–º–æ–±–∏–ª—å —É–∂–µ —É –Ω–∞—Å", "–∫–ª–∏–µ–Ω—Ç –∑–∞–ø–∏—Å–∞–Ω"
            ]
            
            if any(phrase in reasoning_lower for phrase in subsequent_contact_phrases):
                return 'IN.INFO.FU.NOBOOK' if category_num.startswith('IN.') else 'OUT.INFO.FU.NOBOOK', '–ü–û–î–¢–í–ï–†–ñ–î–ï–ù–ò–ï –°–£–©–ï–°–¢–í–£–Æ–©–ï–ô –ó–ê–ü–ò–°–ò - –ø–µ—Ä–µ–∫–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–æ –≤ "–ü–æ—Å–ª–µ–¥—É—é—â–∏–π –∫–æ–Ω—Ç–∞–∫—Ç –ë–ï–ó –∑–∞–ø–∏—Å–∏"'

        return category_num, None

    def safe_save_excel(self, results, output_file):
        """–ë–µ–∑–æ–ø–∞—Å–Ω–æ–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ Excel —Ñ–∞–π–ª–∞ —Å –æ–±—Ä–∞–±–æ—Ç–∫–æ–π —Å–ª—É—á–∞—è, –∫–æ–≥–¥–∞ —Ñ–∞–π–ª –æ—Ç–∫—Ä—ã—Ç"""
        df = pd.DataFrame(results)
        
        # –£–±–∏—Ä–∞–µ–º –∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –∏—Å–∫–ª—é—á–µ–Ω–Ω—ã–µ —Å—Ç–∞–Ω—Ü–∏–∏
        if not df.empty and '–°—Ç–∞–Ω—Ü–∏—è' in df.columns:
            df = df[~df['–°—Ç–∞–Ω—Ü–∏—è'].isin(self.EXCLUDED_STATIONS)]
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Å–ø–∏—Å–æ–∫ —Å—Ç–∞–Ω—Ü–∏–π –¥–ª—è —Å–≤–æ–¥–Ω—ã—Ö —Ç–∞–±–ª–∏—Ü
        if not df.empty and '–°—Ç–∞–Ω—Ü–∏—è' in df.columns:
            stations_order = sorted(df['–°—Ç–∞–Ω—Ü–∏—è'].unique())
        else:
            stations_order = self.ALL_STATIONS
        
        # –°–æ–∑–¥–∞–µ–º —Å–≤–æ–¥–Ω—ã–µ —Ç–∞–±–ª–∏—Ü—ã
        target_summary_df = self.create_summary_table(df, stations_order)
        reference_summary_df = self.create_reference_summary_table(df, stations_order)
        
        # –°–æ–∑–¥–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
        temp_file = None
        try:
            with tempfile.NamedTemporaryFile(suffix='.xlsx', delete=False) as temp_file:
                temp_file_path = temp_file.name
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤–æ –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
            with pd.ExcelWriter(temp_file_path, engine='openpyxl') as writer:
                # 1. –°–≤–æ–¥–Ω–∞—è —Ç–∞–±–ª–∏—Ü–∞ (–¶–µ–ª–µ–≤—ã–µ)
                target_summary_df.to_excel(writer, sheet_name='–°–≤–æ–¥–Ω–∞—è —Ç–∞–±–ª–∏—Ü–∞ (–¶–µ–ª–µ–≤—ã–µ)', index=False)
                
                # 2. –î–µ—Ç–∞–ª—å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
                df.to_excel(writer, sheet_name='–î–µ—Ç–∞–ª—å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ', index=False)
                
                # 3. –°–≤–æ–¥–Ω–∞—è —Ç–∞–±–ª–∏—Ü–∞ (–°–ø—Ä–∞–≤–æ—á–Ω—ã–µ)
                reference_summary_df.to_excel(writer, sheet_name='–°–≤–æ–¥–Ω–∞—è —Ç–∞–±–ª–∏—Ü–∞ (–°–ø—Ä–∞–≤–æ—á–Ω—ã–µ)', index=False)
                
                # –ü—Ä–∏–º–µ–Ω—è–µ–º —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ
                self.apply_excel_formatting(writer, df, target_summary_df, reference_summary_df)
            
            # –ü—ã—Ç–∞–µ–º—Å—è –∑–∞–º–µ–Ω–∏—Ç—å –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π —Ñ–∞–π–ª
            max_attempts = 3
            for attempt in range(max_attempts):
                try:
                    # –ï—Å–ª–∏ —Ñ–∞–π–ª —Å—É—â–µ—Å—Ç–≤—É–µ—Ç, —É–¥–∞–ª—è–µ–º –µ–≥–æ
                    if os.path.exists(output_file):
                        os.remove(output_file)
                    
                    # –ü–µ—Ä–µ–º–µ—â–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª –Ω–∞ –º–µ—Å—Ç–æ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–≥–æ
                    shutil.move(temp_file_path, output_file)
                    print(f"‚úÖ –§–∞–π–ª —É—Å–ø–µ—à–Ω–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {output_file}")
                    return True
                    
                except PermissionError as e:
                    if attempt < max_attempts - 1:
                        print(f"‚ö†Ô∏è –§–∞–π–ª {output_file} –∑–∞–±–ª–æ–∫–∏—Ä–æ–≤–∞–Ω (–≤–æ–∑–º–æ–∂–Ω–æ, –æ—Ç–∫—Ä—ã—Ç –≤ Excel). –ü–æ–ø—ã—Ç–∫–∞ {attempt + 1}/{max_attempts}...")
                        time.sleep(2)  # –ñ–¥–µ–º 2 —Å–µ–∫—É–Ω–¥—ã –ø–µ—Ä–µ–¥ —Å–ª–µ–¥—É—é—â–µ–π –ø–æ–ø—ã—Ç–∫–æ–π
                    else:
                        print(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å —Ñ–∞–π–ª {output_file} –ø–æ—Å–ª–µ {max_attempts} –ø–æ–ø—ã—Ç–æ–∫. –§–∞–π–ª –∑–∞–±–ª–æ–∫–∏—Ä–æ–≤–∞–Ω.")
                        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å –¥—Ä—É–≥–∏–º –∏–º–µ–Ω–µ–º
                        backup_name = output_file.replace('.xlsx', f'_backup_{int(time.time())}.xlsx')
                        shutil.move(temp_file_path, backup_name)
                        print(f"üíæ –§–∞–π–ª —Å–æ—Ö—Ä–∞–Ω–µ–Ω –∫–∞–∫ —Ä–µ–∑–µ—Ä–≤–Ω–∞—è –∫–æ–ø–∏—è: {backup_name}")
                        return False
                        
                except Exception as e:
                    print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ —Ñ–∞–π–ª–∞: {e}")
                    return False
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ –≤—Ä–µ–º–µ–Ω–Ω–æ–≥–æ —Ñ–∞–π–ª–∞: {e}")
            return False
        finally:
            # –£–¥–∞–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª –µ—Å–ª–∏ –æ–Ω –æ—Å—Ç–∞–ª—Å—è
            if temp_file and os.path.exists(temp_file_path):
                try:
                    os.remove(temp_file_path)
                except:
                    pass

    def get_main_group(self, category_num):
        """–û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –≥–ª–∞–≤–Ω–æ–π –≥—Ä—É–ø–ø—ã –ø–æ –Ω–æ–≤–æ–π —Å–∏–º–≤–æ–ª—å–Ω–æ–π —Å—Ö–µ–º–µ"""
        # –ù–µ —Ü–µ–ª–µ–≤—ã–µ
        if category_num in ['IN.NE', 'OUT.NE']:
            return "–ù–µ —Ü–µ–ª–µ–≤—ã–µ"
        # –°–ø—Ä–∞–≤–æ—á–Ω—ã–µ
        elif category_num in ['IN.INFO.FU.NOBOOK', 'OUT.INFO.FU.NOBOOK']:
            return "–°–ø—Ä–∞–≤–æ—á–Ω—ã–µ"
        # –¶–µ–ª–µ–≤—ã–µ (–≤—Å–µ –æ—Å—Ç–∞–ª—å–Ω—ã–µ IN.* –∏ OUT.* –∫—Ä–æ–º–µ NE –∏ INFO)
        elif category_num.startswith('IN.') or category_num.startswith('OUT.'):
            if not category_num.endswith('.NE') and 'INFO' not in category_num:
                return "–¶–µ–ª–µ–≤—ã–µ"
        
        # –î–ª—è —Å—Ç–∞—Ä—ã—Ö —á–∏—Å–ª–æ–≤—ã—Ö –∫–æ–¥–æ–≤ (–æ–±—Ä–∞—Ç–Ω–∞—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å)
        if category_num == "1":
            return "–ù–µ —Ü–µ–ª–µ–≤—ã–µ"
        elif category_num in ["12", "13"]:
            return "–°–ø—Ä–∞–≤–æ—á–Ω—ã–µ"
        elif category_num in ["2", "3", "4", "5", "6", "7", "8", "9", "10", "11", "14"]:
            return "–¶–µ–ª–µ–≤—ã–µ"

        return "–ù–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω"

    def get_target_status(self, category_num):
        """–û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Å—Ç–∞—Ç—É—Å–∞ –¶–µ–ª–µ–≤–æ–π/–ù–µ —Ü–µ–ª–µ–≤–æ–π/–°–ø—Ä–∞–≤–æ—á–Ω—ã–µ –ø–æ –Ω–æ–≤–æ–π —Å—Ö–µ–º–µ"""
        # –ù–µ —Ü–µ–ª–µ–≤—ã–µ
        if category_num in ['IN.NE', 'OUT.NE']:
            return "–ù–µ —Ü–µ–ª–µ–≤—ã–µ"
        # –°–ø—Ä–∞–≤–æ—á–Ω—ã–µ
        elif category_num in ['IN.INFO.FU.NOBOOK', 'OUT.INFO.FU.NOBOOK']:
            return "–°–ø—Ä–∞–≤–æ—á–Ω—ã–µ"
        # –¶–µ–ª–µ–≤—ã–µ (–≤—Å–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ –∫–æ–Ω—Å—É–ª—å—Ç–∞—Ü–∏–π, –∑–∞–ø–∏—Å–µ–π –∏ –æ–±–∑–≤–æ–Ω–æ–≤)
        elif category_num in ['IN.BOOK', 'OUT.BOOK', 'IN.FU.BOOK', 'OUT.FU.BOOK',
                              'OUT.OBZ.BOOK', 'OUT.OBZ.NOBOOK',
                              'IN.CONS.MSG', 'IN.CONS.REDIR', 'IN.CONS.OWN', 'IN.CONS.THINK',
                              'IN.CONS.BUSY', 'IN.CONS.COST', 'IN.CONS.NODO', 'IN.CONS.CB', 'IN.CONS.OTHER',
                              'OUT.CONS.MSG', 'OUT.CONS.REDIR', 'OUT.CONS.OWN', 'OUT.CONS.THINK',
                              'OUT.CONS.BUSY', 'OUT.CONS.COST', 'OUT.CONS.NODO', 'OUT.CONS.CB', 'OUT.CONS.OTHER']:
            return "–¶–µ–ª–µ–≤—ã–µ"
        
        # –î–ª—è —Å—Ç–∞—Ä—ã—Ö —á–∏—Å–ª–æ–≤—ã—Ö –∫–æ–¥–æ–≤ (–æ–±—Ä–∞—Ç–Ω–∞—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å)
        category_name = self.get_category_name(category_num)
        return self.get_category_group(category_name)

    def get_recorded_status(self, category_num):
        """–û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Å—Ç–∞—Ç—É—Å–∞ –ó–∞–ø–∏—Å–∞–Ω/–ù–µ –∑–∞–ø–∏—Å–∞–Ω –ø–æ –Ω–æ–≤–æ–π —Å—Ö–µ–º–µ"""
        # –ó–∞–ø–∏—Å–∞–Ω - —Ç–æ–ª—å–∫–æ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ —Å –∑–∞–ø–∏—Å—å—é (BOOK, –Ω–æ –Ω–µ INFO.FU.NOBOOK)
        if category_num in ['IN.BOOK', 'OUT.BOOK', 'IN.FU.BOOK', 'OUT.FU.BOOK', 'OUT.OBZ.BOOK']:
            return "–ó–∞–ø–∏—Å–∞–Ω"
        
        # –î–ª—è —Å—Ç–∞—Ä—ã—Ö —á–∏—Å–ª–æ–≤—ã—Ö –∫–æ–¥–æ–≤ (–æ–±—Ä–∞—Ç–Ω–∞—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å)
        if category_num in ["11", "24"]:
            return "–ó–∞–ø–∏—Å–∞–Ω"

        return "–ù–µ –∑–∞–ø–∏—Å–∞–Ω"

    def process_folder(self, input_folder, output_file, context_days=7, progress_callback=None):
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ –ø–∞–ø–∫–∏ —Å —Ñ–∞–π–ª–∞–º–∏ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–π"""
        results = []
        total_calls = 0

        # –ó–∞–≥—Ä—É–∂–∞–µ–º –∏—Å—Ç–æ—Ä–∏—é –∑–≤–æ–Ω–∫–æ–≤ –∑–∞ —É–∫–∞–∑–∞–Ω–Ω—ã–π –ø–µ—Ä–∏–æ–¥ —Ç–æ–ª—å–∫–æ –∏–∑ –ø–∞–ø–∫–∏ uploads –¥–ª—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
        external_history = []
        if context_days > 0:  # –ï—Å–ª–∏ context_days = 0, –Ω–µ –∑–∞–≥—Ä—É–∂–∞–µ–º –∏—Å—Ç–æ—Ä–∏—é
            try:
                uploads_dir = Path(self.rules_manager.db_path).resolve().parent / "uploads"
                frames = []
                if uploads_dir.exists():
                    for f in sorted(uploads_dir.glob("*.xlsx"), key=lambda p: p.stat().st_mtime, reverse=True):
                        try:
                            try:
                                one_df = pd.read_excel(f, sheet_name='–î–µ—Ç–∞–ª—å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ')
                            except Exception:
                                one_df = pd.read_excel(f)
                            if one_df is not None and not one_df.empty:
                                frames.append(one_df)
                        except Exception:
                            continue
                all_df = pd.concat(frames, ignore_index=True) if frames else pd.DataFrame()
                
                if not all_df.empty:
                    # –§–∏–ª—å—Ç—Ä—É–µ–º –ø–æ –ø–µ—Ä–∏–æ–¥—É (–Ω–µ –≤–∫–ª—é—á–∞—è —Ç–µ–∫—É—â–∏–π –¥–µ–Ω—å)
                    # –ò—Å–ø–æ–ª—å–∑—É–µ–º –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Å–≤–µ—Ä—Ö—É datetime/timedelta, –∞ –Ω–µ –ª–æ–∫–∞–ª—å–Ω—ã–π –∏–º–ø–æ—Ä—Ç
                    today = datetime.now().date()
                    cutoff_date = today - timedelta(days=context_days)
                    
                    # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –¥–∞—Ç—ã –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è, –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—è –æ—à–∏–±–∫–∏
                    # –ò—Å–ø–æ–ª—å–∑—É–µ–º errors='coerce' —á—Ç–æ–±—ã –Ω–µ–≤–∞–ª–∏–¥–Ω—ã–µ –¥–∞—Ç—ã —Å—Ç–∞–ª–∏ NaT (Not a Time)
                    all_df['–î–∞—Ç–∞_parsed'] = pd.to_datetime(all_df['–î–∞—Ç–∞'], format='%d.%m.%Y', errors='coerce').dt.date
                    
                    # –§–∏–ª—å—Ç—Ä—É–µ–º —Ç–æ–ª—å–∫–æ —Å—Ç—Ä–æ–∫–∏ —Å –≤–∞–ª–∏–¥–Ω—ã–º–∏ –¥–∞—Ç–∞–º–∏
                    valid_dates_mask = all_df['–î–∞—Ç–∞_parsed'].notna()
                    all_df_valid = all_df[valid_dates_mask].copy()
                    
                    if not all_df_valid.empty:
                        filtered_df = all_df_valid[all_df_valid['–î–∞—Ç–∞_parsed'] < today]  # –ò—Å–∫–ª—é—á–∞–µ–º —Ç–µ–∫—É—â–∏–π –¥–µ–Ω—å
                        
                        if context_days < 90:  # –ï—Å–ª–∏ –Ω–µ "–≤—Å–µ –¥–∞–Ω–Ω—ã–µ" (90 –¥–Ω–µ–π = –≤—Å–µ –¥–∞–Ω–Ω—ã–µ)
                            filtered_df = filtered_df[filtered_df['–î–∞—Ç–∞_parsed'] >= cutoff_date]
                    else:
                        filtered_df = pd.DataFrame()  # –ü—É—Å—Ç–æ–π DataFrame, –µ—Å–ª–∏ –Ω–µ—Ç –≤–∞–ª–∏–¥–Ω—ã—Ö –¥–∞—Ç
                    
                    # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ –Ω—É–∂–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç –¥–ª—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ (–ù–ï –≤–∫–ª—é—á–∞–µ–º –≤ –æ—Ç—á–µ—Ç)
                    if not filtered_df.empty:
                        for _, row in filtered_df.iterrows():
                            call_record = {
                                '–§–∞–π–ª': str(row.get('–§–∞–π–ª', 'external')),
                                '–ù–æ–º–µ—Ä —Ç–µ–ª–µ—Ñ–æ–Ω–∞': str(row.get('–ù–æ–º–µ—Ä —Ç–µ–ª–µ—Ñ–æ–Ω–∞', '')),
                                '–î–∞—Ç–∞': str(row.get('–î–∞—Ç–∞', '')),
                                '–í—Ä–µ–º—è': str(row.get('–í—Ä–µ–º—è', '')),
                                '–ù–æ–º–µ—Ä —Å—Ç–∞–Ω—Ü–∏–∏': str(row.get('–ù–æ–º–µ—Ä —Å—Ç–∞–Ω—Ü–∏–∏', '')),
                                '–°—Ç–∞–Ω—Ü–∏—è': str(row.get('–°—Ç–∞–Ω—Ü–∏—è', '')),
                                '–†–µ–∑—É–ª—å—Ç–∞—Ç': str(row.get('–†–µ–∑—É–ª—å—Ç–∞—Ç', '')),
                                '–ö–∞—Ç–µ–≥–æ—Ä–∏—è': str(row.get('–ö–∞—Ç–µ–≥–æ—Ä–∏—è', '')),
                                '–¶–µ–ª–µ–≤–æ–π/–ù–µ —Ü–µ–ª–µ–≤–æ–π': str(row.get('–¶–µ–ª–µ–≤–æ–π/–ù–µ —Ü–µ–ª–µ–≤–æ–π', '')),
                                '–ó–∞–ø–∏—Å–∞–Ω/–ù–µ –∑–∞–ø–∏—Å–∞–Ω': str(row.get('–ó–∞–ø–∏—Å–∞–Ω/–ù–µ –∑–∞–ø–∏—Å–∞–Ω', '')),
                                '–û–±–æ—Å–Ω–æ–≤–∞–Ω–∏–µ': str(row.get('–û–±–æ—Å–Ω–æ–≤–∞–Ω–∏–µ', ''))
                            }
                            external_history.append(call_record)
                    
                    print(f"–ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(external_history)} –∑–≤–æ–Ω–∫–æ–≤ –∏–∑ –∏—Å—Ç–æ—Ä–∏–∏ –∑–∞ {context_days} –¥–Ω–µ–π –¥–ª—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞")
                    
            except Exception as e:
                print(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –∏—Å—Ç–æ—Ä–∏–∏: {e}")

        # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ —Ç–µ–∫—Å—Ç–æ–≤—ã–µ —Ñ–∞–π–ª—ã –≤ –ø–∞–ø–∫–µ
        if not os.path.exists(input_folder):
            raise FileNotFoundError(f"–ü–∞–ø–∫–∞ {input_folder} –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")
        
        text_files = [f for f in os.listdir(input_folder) if f.endswith('.txt')]
        
        if not text_files:
            raise ValueError(f"–í –ø–∞–ø–∫–µ {input_folder} –Ω–µ –Ω–∞–π–¥–µ–Ω–æ .txt —Ñ–∞–π–ª–æ–≤")

        # –°–æ—Ä—Ç–∏—Ä—É–µ–º —Ñ–∞–π–ª—ã –ø–æ –¥–∞—Ç–µ –∏ –≤—Ä–µ–º–µ–Ω–∏ –∑–≤–æ–Ω–∫–∞, –∏–∑–≤–ª–µ—á—ë–Ω–Ω—ã–º –∏–∑ –∏–º–µ–Ω–∏ —Ñ–∞–π–ª–∞
        def _sort_key_by_datetime(filename):
            try:
                _, call_date, call_time, _, _, _ = self.extract_file_info(filename)
                dt = datetime.strptime(f"{call_date} {call_time}", "%d.%m.%Y %H:%M")
                return (dt, filename)
            except Exception:
                # –ï—Å–ª–∏ –Ω–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–æ–∑–Ω–∞—Ç—å –¥–∞—Ç—É/–≤—Ä–µ–º—è ‚Äî –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º –≤ –Ω–∞—á–∞–ª–æ, —Å–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –∏–º–µ–Ω–∏
                return (datetime.min, filename)

        text_files.sort(key=_sort_key_by_datetime)

        print(f"–ù–∞–π–¥–µ–Ω–æ {len(text_files)} —Ñ–∞–π–ª–æ–≤ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏...")

        for i, filename in enumerate(text_files, 1):
            if progress_callback:
                progress_callback(i, len(text_files), f"–û–±—Ä–∞–±–æ—Ç–∫–∞ {filename}")
            
            print(f"–û–±—Ä–∞–±–æ—Ç–∫–∞ —Ñ–∞–π–ª–∞ {i}/{len(text_files)}: {filename}")
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏–∑ –∏–º–µ–Ω–∏ —Ñ–∞–π–ª–∞
            phone_number, call_date, call_time, station_number, station_name, call_type = self.extract_file_info(filename)
            
            # –ß–∏—Ç–∞–µ–º —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—é
            try:
                with open(os.path.join(input_folder, filename), 'r', encoding='utf-8') as f:
                    transcription = f.read().strip()
            except UnicodeDecodeError:
                try:
                    with open(os.path.join(input_folder, filename), 'r', encoding='cp1251') as f:
                        transcription = f.read().strip()
                except:
                    transcription = "–û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è —Ñ–∞–π–ª–∞"
            
            if not transcription or transcription == "–û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è —Ñ–∞–π–ª–∞":
                results.append({
                    '–§–∞–π–ª': filename,
                    '–ù–æ–º–µ—Ä —Ç–µ–ª–µ—Ñ–æ–Ω–∞': phone_number,
                    '–î–∞—Ç–∞': call_date,
                    '–í—Ä–µ–º—è': call_time,
                    '–ù–æ–º–µ—Ä —Å—Ç–∞–Ω—Ü–∏–∏': station_number,
                    '–°—Ç–∞–Ω—Ü–∏—è': station_name,
                    '–¢–∏–ø –∑–≤–æ–Ω–∫–∞': call_type,
                    '–†–µ–∑—É–ª—å—Ç–∞—Ç': '–ü—Ä–æ–ø—É—â–µ–Ω',
                    '–ö–∞—Ç–µ–≥–æ—Ä–∏—è': '–ü—É—Å—Ç–æ–π —Ñ–∞–π–ª',
                    '–¶–µ–ª–µ–≤–æ–π/–ù–µ —Ü–µ–ª–µ–≤–æ–π': '–ù–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω',
                    '–ó–∞–ø–∏—Å–∞–Ω/–ù–µ –∑–∞–ø–∏—Å–∞–Ω': '–ù–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω',
                    '–û–±–æ—Å–Ω–æ–≤–∞–Ω–∏–µ': '–§–∞–π–ª –ø—É—Å—Ç–æ–π –∏–ª–∏ –Ω–µ —á–∏—Ç–∞–µ—Ç—Å—è'
                })
                continue
            
            total_calls += 1
            
            # –û–±—ä–µ–¥–∏–Ω—è–µ–º —Ç–µ–∫—É—â–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å –≤–Ω–µ—à–Ω–µ–π –∏—Å—Ç–æ—Ä–∏–µ–π –¥–ª—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
            combined_history = external_history + results

            # –°—Ç—Ä–æ–∏–º –∫–æ–Ω—Ç–µ–∫—Å—Ç –ø—Ä–µ–¥—ã–¥—É—â–∏—Ö –∑–≤–æ–Ω–∫–æ–≤ –∫–ª–∏–µ–Ω—Ç–∞
            call_history_context = self.build_call_history_context(phone_number, filename, combined_history)
            
            # –°—Ç—Ä–æ–∏–º –∫–æ–Ω—Ç–µ–∫—Å—Ç —Å –æ–±—É—á–∞—é—â–∏–º–∏ –ø—Ä–∏–º–µ—Ä–∞–º–∏
            training_examples_context = self.build_training_examples_context(transcription)

            # –ö–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä—É–µ–º –∑–≤–æ–Ω–æ–∫ —Å —É—á–µ—Ç–æ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –∏ –æ–±—É—á–∞—é—â–∏—Ö –ø—Ä–∏–º–µ—Ä–æ–≤
            category_num, reasoning = self.classify_call_with_reasoning(
                transcription, call_history_context, training_examples_context, call_type
            )

            # –ö–†–ò–¢–ò–ß–ï–°–ö–ê–Ø –ü–†–û–í–ï–†–ö–ê: –ü–æ–≤—Ç–æ—Ä–Ω—ã–µ –∑–≤–æ–Ω–∫–∏ –í–°–ï–ì–î–ê –ø–µ—Ä–µ–∫–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä—É–µ–º
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –í–°–Æ –∏—Å—Ç–æ—Ä–∏—é (–≤–∫–ª—é—á–∞—è –≤–Ω–µ—à–Ω—é—é –∏—Å—Ç–æ—Ä–∏—é –∑–∞ –ø–µ—Ä–∏–æ–¥ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞)
            client_all_previous_calls = [call for call in combined_history
                                       if call['–ù–æ–º–µ—Ä —Ç–µ–ª–µ—Ñ–æ–Ω–∞'] == phone_number and call['–§–∞–π–ª'] != filename]
            
            if client_all_previous_calls and phone_number and phone_number != "–ù–µ —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω":
                # –ï—Å–ª–∏ –µ—Å—Ç—å –∏—Å—Ç–æ—Ä–∏—è (–≤–Ω–µ—à–Ω—è—è + —Ç–µ–∫—É—â–∞—è —Å–µ—Å—Å–∏—è) - –ø—Ä–æ–≤–µ—Ä—è–µ–º, –Ω—É–∂–Ω–æ –ª–∏ –ø–µ—Ä–µ–∫–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞—Ç—å
                if category_num not in ['IN.FU.BOOK', 'OUT.FU.BOOK', 'IN.INFO.FU.NOBOOK', 'OUT.INFO.FU.NOBOOK', 'IN.NE', 'OUT.NE']:
                    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –∏–∑ —Ç–µ–∫—É—â–µ–π –∫–∞—Ç–µ–≥–æ—Ä–∏–∏
                    direction_prefix = 'IN.' if category_num.startswith('IN.') or (category_num.isdigit() and int(category_num) <= 13) else 'OUT.'
                    
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –±—ã–ª–∞ –ª–∏ –ó–ê–ü–ò–°–¨ –≤ –∏—Å—Ç–æ—Ä–∏–∏
                    has_previous_record = any(
                        call.get('–†–µ–∑—É–ª—å—Ç–∞—Ç') in ['IN.BOOK', 'OUT.BOOK', 'IN.FU.BOOK', 'OUT.FU.BOOK', '2', '15'] 
                        for call in client_all_previous_calls
                    )
                    
                    # –ï—Å–ª–∏ AI –∫–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–ª –∫–∞–∫ –Ω–æ–≤—É—é –∑–∞–ø–∏—Å—å (BOOK)
                    if category_num in ['IN.BOOK', 'OUT.BOOK']:
                        if has_previous_record:
                            category_num = f'{direction_prefix}INFO.FU.NOBOOK'
                        else:
                            category_num = f'{direction_prefix}FU.BOOK'
                    else:
                        # –õ—é–±–∞—è –∫–æ–Ω—Å—É–ª—å—Ç–∞—Ü–∏—è/—É—Ç–æ—á–Ω–µ–Ω–∏–µ –ø—Ä–∏ –Ω–∞–ª–∏—á–∏–∏ –∏—Å—Ç–æ—Ä–∏–∏
                        category_num = f'{direction_prefix}INFO.FU.NOBOOK'

            # –ü–æ–ª—É—á–∞–µ–º –æ–ø–∏—Å–∞–Ω–∏–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏
            category_desc = self.get_category_description(category_num)

            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Å—Ç–∞—Ç—É—Å—ã
            target_status = self.get_target_status(category_num)
            recorded_status = self.get_recorded_status(category_num)

            # –î–æ–±–∞–≤–ª—è–µ–º –∑–∞–¥–µ—Ä–∂–∫—É –º–µ–∂–¥—É –∑–∞–ø—Ä–æ—Å–∞–º–∏
            time.sleep(1)

            results.append({
                '–§–∞–π–ª': filename,
                '–ù–æ–º–µ—Ä —Ç–µ–ª–µ—Ñ–æ–Ω–∞': phone_number,
                '–î–∞—Ç–∞': call_date,
                '–í—Ä–µ–º—è': call_time,
                '–ù–æ–º–µ—Ä —Å—Ç–∞–Ω—Ü–∏–∏': station_number,
                '–°—Ç–∞–Ω—Ü–∏—è': station_name,
                '–¢–∏–ø –∑–≤–æ–Ω–∫–∞': call_type,
                '–†–µ–∑—É–ª—å—Ç–∞—Ç': category_num,
                '–ö–∞—Ç–µ–≥–æ—Ä–∏—è': category_desc,
                '–¶–µ–ª–µ–≤–æ–π/–ù–µ —Ü–µ–ª–µ–≤–æ–π': target_status,
                '–ó–∞–ø–∏—Å–∞–Ω/–ù–µ –∑–∞–ø–∏—Å–∞–Ω': recorded_status,
                '–û–±–æ—Å–Ω–æ–≤–∞–Ω–∏–µ': reasoning
            })
        
        # –û–±–Ω–æ–≤–ª—è–µ–º –º–µ—Ç—Ä–∏–∫–∏ –≤ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö
        today = datetime.now().strftime('%Y-%m-%d')
        self.training_manager.update_daily_metrics(today, total_calls, total_calls, 0)
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤ Excel
        self.save_results_to_excel(results, output_file)
        
        return results, 0, total_calls

    def save_results_to_excel(self, results, output_file):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –≤ Excel —Å —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ–º"""
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –±–µ–∑–æ–ø–∞—Å–Ω–æ–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ
        success = self.safe_save_excel(results, output_file)
        if not success:
            print(f"‚ö†Ô∏è –í–Ω–∏–º–∞–Ω–∏–µ: –§–∞–π–ª {output_file} –Ω–µ —É–¥–∞–ª–æ—Å—å –ø–µ—Ä–µ–∑–∞–ø–∏—Å–∞—Ç—å. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ, –Ω–µ –æ—Ç–∫—Ä—ã—Ç –ª–∏ –æ–Ω –≤ Excel.")

    def create_summary_table(self, results_df, stations_order=None):
        """–°–æ–∑–¥–∞–Ω–∏–µ —Å–≤–æ–¥–Ω–æ–π —Ç–∞–±–ª–∏—Ü—ã –ø–æ —Å—Ç–∞–Ω—Ü–∏—è–º –∏ –ø—Ä–∏—á–∏–Ω–∞–º —Å–æ–≥–ª–∞—Å–Ω–æ –Ω–æ–≤–æ–π —Å—Ö–µ–º–µ.
        
        stations_order: —Å–ø–∏—Å–æ–∫ –Ω–∞–∑–≤–∞–Ω–∏–π —Å—Ç–∞–Ω—Ü–∏–π –≤ –Ω—É–∂–Ω–æ–º –ø–æ—Ä—è–¥–∫–µ. 
        –ï—Å–ª–∏ –Ω–µ –ø–µ—Ä–µ–¥–∞–Ω, –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è self.ALL_STATIONS –∏–ª–∏ —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ —Å—Ç–∞–Ω—Ü–∏–∏ –∏–∑ –¥–∞–Ω–Ω—ã—Ö.
        """
        summary_data = []
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –ø–æ—Ä—è–¥–æ–∫ —Å—Ç–∞–Ω—Ü–∏–π
        if stations_order is not None:
            stations = stations_order
        elif not results_df.empty and '–°—Ç–∞–Ω—Ü–∏—è' in results_df.columns:
            stations = sorted(results_df['–°—Ç–∞–Ω—Ü–∏—è'].unique())
        else:
            stations = self.ALL_STATIONS
        
        # –¶–ï–õ–ï–í–´–ï –ó–í–û–ù–ö–ò (–æ–±—ä–µ–¥–∏–Ω–µ–Ω–Ω—ã–µ –≤—Ö–æ–¥—è—â–∏–µ –∏ –∏—Å—Ö–æ–¥—è—â–∏–µ)
        summary_data.append(['–¶–µ–ª–µ–≤—ã–µ', ''] + [''] * len(stations))
        
        # –ó–∞–ø–∏—Å–∞–Ω–Ω—ã–µ (–≤—Ö–æ–¥—è—â–∏–µ + –∏—Å—Ö–æ–¥—è—â–∏–µ)
        recorded_calls = results_df[results_df['–ó–∞–ø–∏—Å–∞–Ω/–ù–µ –∑–∞–ø–∏—Å–∞–Ω'] == '–ó–∞–ø–∏—Å–∞–Ω']
        recorded_counts = recorded_calls['–°—Ç–∞–Ω—Ü–∏—è'].value_counts().reindex(stations, fill_value=0)
        summary_data.append(['  - –ó–∞–ø–∏—Å–∞–Ω–Ω—ã–µ', recorded_counts.sum()] + recorded_counts.tolist())
        
        # –ù–µ –∑–∞–ø–∏—Å–∞–Ω–Ω—ã–µ - —Å—É–º–º–∞ –≤—Å–µ—Ö –∫–æ–Ω—Å—É–ª—å—Ç–∞—Ü–∏–π
        consultation_categories = {
            '–ö–æ–Ω—Å—É–ª—å—Ç–∞—Ü–∏—è - –ü–ï–†–ï–®–õ–ò –í –ú–ï–°–°–ï–ù–î–ñ–ï–†': ['IN.CONS.MSG', 'OUT.CONS.MSG'],
            '–ö–æ–Ω—Å—É–ª—å—Ç–∞—Ü–∏—è - –ü–ï–†–ï–ê–î–†–ï–°–ê–¶–ò–Ø': ['IN.CONS.REDIR', 'OUT.CONS.REDIR'],
            '–ö–æ–Ω—Å—É–ª—å—Ç–∞—Ü–∏—è - –°–í–û–ò –ó–ê–ü–ß–ê–°–¢–ò': ['IN.CONS.OWN', 'OUT.CONS.OWN'],
            '–ö–æ–Ω—Å—É–ª—å—Ç–∞—Ü–∏—è - –ü–û–î–£–ú–ê–ï–¢/–û–¢–ö–ê–ó': ['IN.CONS.THINK', 'OUT.CONS.THINK'],
            '–ö–æ–Ω—Å—É–ª—å—Ç–∞—Ü–∏—è - –ù–ï–¢ –í–†–ï–ú–ï–ù–ò/–ó–ê–ù–Ø–¢–û': ['IN.CONS.BUSY', 'OUT.CONS.BUSY'],
            '–ö–æ–Ω—Å—É–ª—å—Ç–∞—Ü–∏—è - –í–´–°–û–ö–ê–Ø –°–¢–û–ò–ú–û–°–¢–¨': ['IN.CONS.COST', 'OUT.CONS.COST'],
            '–ö–æ–Ω—Å—É–ª—å—Ç–∞—Ü–∏—è - –ù–ï –í–´–ü–û–õ–ù–Ø–ï–ú –†–ê–ë–û–¢–´': ['IN.CONS.NODO', 'OUT.CONS.NODO'],
            '–ö–æ–Ω—Å—É–ª—å—Ç–∞—Ü–∏—è - –ó–ê–ü–õ–ê–ù–ò–†–û–í–ê–ù –ü–ï–†–ï–ó–í–û–ù': ['IN.CONS.CB', 'OUT.CONS.CB'],
            '–ö–æ–Ω—Å—É–ª—å—Ç–∞—Ü–∏—è - –û–±—â–∞—è': ['IN.CONS.OTHER', 'OUT.CONS.OTHER']
        }
        
        # –°–æ–±–∏—Ä–∞–µ–º –≤—Å–µ –∫–æ–¥—ã –∫–æ–Ω—Å—É–ª—å—Ç–∞—Ü–∏–π
        all_consultation_codes = []
        for cat_codes in consultation_categories.values():
            all_consultation_codes.extend(cat_codes)
        
        # –ù–µ –∑–∞–ø–∏—Å–∞–Ω–Ω—ã–µ = –≤—Å–µ –∫–æ–Ω—Å—É–ª—å—Ç–∞—Ü–∏–∏
        not_recorded_calls = results_df[results_df['–†–µ–∑—É–ª—å—Ç–∞—Ç'].isin(all_consultation_codes)]
        not_recorded_counts = not_recorded_calls['–°—Ç–∞–Ω—Ü–∏—è'].value_counts().reindex(stations, fill_value=0)
        summary_data.append(['  - –ù–µ –∑–∞–ø–∏—Å–∞–Ω–Ω—ã–µ', not_recorded_counts.sum()] + not_recorded_counts.tolist())
        
        # –î–µ—Ç–∞–ª–∏–∑–∞—Ü–∏—è –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º –∫–æ–Ω—Å—É–ª—å—Ç–∞—Ü–∏–π
        for cat_name, cat_codes in consultation_categories.items():
            cat_calls = results_df[results_df['–†–µ–∑—É–ª—å—Ç–∞—Ç'].isin(cat_codes)]
            cat_counts = cat_calls['–°—Ç–∞–Ω—Ü–∏—è'].value_counts().reindex(stations, fill_value=0)
            summary_data.append([f'    {cat_name}', cat_counts.sum()] + cat_counts.tolist())
        
        columns = ['–ö–∞—Ç–µ–≥–æ—Ä–∏—è', '–ö–æ–ª-–≤–æ'] + stations
        summary_df = pd.DataFrame(summary_data, columns=columns)
        
        return summary_df

    def create_reference_summary_table(self, results_df, stations_order=None):
        """–°–æ–∑–¥–∞–Ω–∏–µ —Å–≤–æ–¥–Ω–æ–π —Ç–∞–±–ª–∏—Ü—ã –¥–ª—è —Å–ø—Ä–∞–≤–æ—á–Ω—ã—Ö –∑–≤–æ–Ω–∫–æ–≤ —Å–æ–≥–ª–∞—Å–Ω–æ –Ω–æ–≤–æ–π —Å—Ö–µ–º–µ.
        
        stations_order: —Å–ø–∏—Å–æ–∫ –Ω–∞–∑–≤–∞–Ω–∏–π —Å—Ç–∞–Ω—Ü–∏–π –≤ –Ω—É–∂–Ω–æ–º –ø–æ—Ä—è–¥–∫–µ. 
        –ï—Å–ª–∏ –Ω–µ –ø–µ—Ä–µ–¥–∞–Ω, –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è self.ALL_STATIONS –∏–ª–∏ —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ —Å—Ç–∞–Ω—Ü–∏–∏ –∏–∑ –¥–∞–Ω–Ω—ã—Ö.
        """
        # –†–∞–∑–¥–µ–ª—è–µ–º —Å–ø—Ä–∞–≤–æ—á–Ω—ã–µ –∑–≤–æ–Ω–∫–∏ –ø–æ —Ç–∏–ø–∞–º
        incoming_reference = results_df[(results_df['–¶–µ–ª–µ–≤–æ–π/–ù–µ —Ü–µ–ª–µ–≤–æ–π'] == '–°–ø—Ä–∞–≤–æ—á–Ω—ã–µ') & (results_df['–¢–∏–ø –∑–≤–æ–Ω–∫–∞'] == '–í—Ö–æ–¥—è—â–∏–π')]
        outgoing_reference = results_df[(results_df['–¶–µ–ª–µ–≤–æ–π/–ù–µ —Ü–µ–ª–µ–≤–æ–π'] == '–°–ø—Ä–∞–≤–æ—á–Ω—ã–µ') & (results_df['–¢–∏–ø –∑–≤–æ–Ω–∫–∞'] == '–ò—Å—Ö–æ–¥—è—â–∏–π')]
        
        summary_data = []
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –ø–æ—Ä—è–¥–æ–∫ —Å—Ç–∞–Ω—Ü–∏–π
        if stations_order is not None:
            stations = stations_order
        elif not results_df.empty and '–°—Ç–∞–Ω—Ü–∏—è' in results_df.columns:
            stations = sorted(results_df['–°—Ç–∞–Ω—Ü–∏—è'].unique())
        else:
            stations = self.ALL_STATIONS
        
        # –í–•–û–î–Ø–©–ò–ï –°–ü–†–ê–í–û–ß–ù–´–ï
        summary_data.append(['=== –í–•–û–î–Ø–©–ò–ï –°–ü–†–ê–í–û–ß–ù–´–ï ===', ''] + [''] * len(stations))
        
        total_incoming_ref = incoming_reference['–°—Ç–∞–Ω—Ü–∏—è'].value_counts().reindex(stations, fill_value=0)
        summary_data.append(['–í—Å–µ–≥–æ –≤—Ö–æ–¥—è—â–∏—Ö —Å–ø—Ä–∞–≤–æ—á–Ω—ã—Ö', total_incoming_ref.sum()] + total_incoming_ref.tolist())
        
        # –í—Ö–æ–¥—è—â–∏–µ —Å–ø—Ä–∞–≤–æ—á–Ω—ã–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ —Å –Ω–æ–≤—ã–º–∏ —Å–∏–º–≤–æ–ª—å–Ω—ã–º–∏ –∫–æ–¥–∞–º–∏
        incoming_ref_categories = {
            "IN.INFO.FU.NOBOOK": "–ü–æ—Å–ª–µ–¥—É—é—â–∏–π –∫–æ–Ω—Ç–∞–∫—Ç –±–µ–∑ –∑–∞–ø–∏—Å–∏"
        }
        
        for cat_id, cat_name in incoming_ref_categories.items():
            cat_calls = incoming_reference[incoming_reference['–†–µ–∑—É–ª—å—Ç–∞—Ç'] == cat_id]
            cat_counts = cat_calls['–°—Ç–∞–Ω—Ü–∏—è'].value_counts().reindex(stations, fill_value=0)
            summary_data.append([f'  {cat_name}', cat_counts.sum()] + cat_counts.tolist())
        
        # –ò–°–•–û–î–Ø–©–ò–ï –°–ü–†–ê–í–û–ß–ù–´–ï
        summary_data.append(['=== –ò–°–•–û–î–Ø–©–ò–ï –°–ü–†–ê–í–û–ß–ù–´–ï ===', ''] + [''] * len(stations))
        
        total_outgoing_ref = outgoing_reference['–°—Ç–∞–Ω—Ü–∏—è'].value_counts().reindex(stations, fill_value=0)
        summary_data.append(['–í—Å–µ–≥–æ –∏—Å—Ö–æ–¥—è—â–∏—Ö —Å–ø—Ä–∞–≤–æ—á–Ω—ã—Ö', total_outgoing_ref.sum()] + total_outgoing_ref.tolist())
        
        # –ò—Å—Ö–æ–¥—è—â–∏–µ —Å–ø—Ä–∞–≤–æ—á–Ω—ã–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ —Å –Ω–æ–≤—ã–º–∏ —Å–∏–º–≤–æ–ª—å–Ω—ã–º–∏ –∫–æ–¥–∞–º–∏
        outgoing_ref_categories = {
            "OUT.INFO.FU.NOBOOK": "–ü–æ—Å–ª–µ–¥—É—é—â–∏–π –∫–æ–Ω—Ç–∞–∫—Ç –±–µ–∑ –∑–∞–ø–∏—Å–∏",
            "OUT.OBZ.BOOK": "–û–±–∑–≤–æ–Ω - –° –∑–∞–ø–∏—Å—å—é",
            "OUT.OBZ.NOBOOK": "–û–±–∑–≤–æ–Ω - –ë–µ–∑ –∑–∞–ø–∏—Å–∏"
        }
        
        for cat_id, cat_name in outgoing_ref_categories.items():
            cat_calls = outgoing_reference[outgoing_reference['–†–µ–∑—É–ª—å—Ç–∞—Ç'] == cat_id]
            cat_counts = cat_calls['–°—Ç–∞–Ω—Ü–∏—è'].value_counts().reindex(stations, fill_value=0)
            summary_data.append([f'  {cat_name}', cat_counts.sum()] + cat_counts.tolist())
        
        # –ò–¢–û–ì–û –°–ü–†–ê–í–û–ß–ù–´–•
        summary_data.append(['=== –ò–¢–û–ì–û –°–ü–†–ê–í–û–ß–ù–´–• ===', ''] + [''] * len(stations))
        
        all_reference = results_df[results_df['–¶–µ–ª–µ–≤–æ–π/–ù–µ —Ü–µ–ª–µ–≤–æ–π'] == '–°–ø—Ä–∞–≤–æ—á–Ω—ã–µ']
        total_all_ref = all_reference['–°—Ç–∞–Ω—Ü–∏—è'].value_counts().reindex(stations, fill_value=0)
        summary_data.append(['–í—Å–µ–≥–æ —Å–ø—Ä–∞–≤–æ—á–Ω—ã—Ö –∑–≤–æ–Ω–∫–æ–≤', total_all_ref.sum()] + total_all_ref.tolist())
        
        columns = ['–ö–∞—Ç–µ–≥–æ—Ä–∏—è', '–ö–æ–ª-–≤–æ'] + stations
        reference_summary_df = pd.DataFrame(summary_data, columns=columns)
        
        return reference_summary_df

    def apply_excel_formatting(self, writer, df, target_summary_df, reference_summary_df):
        """–ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –∫ Excel —Ñ–∞–π–ª—É"""
        # –¶–≤–µ—Ç–∞ –¥–ª—è –≥—Ä—É–ø–ø
        colors = {
            '–ù–µ —Ü–µ–ª–µ–≤–æ–π': PatternFill(start_color='FFCCCC', end_color='FFCCCC', fill_type='solid'),
            '–¶–µ–ª–µ–≤–æ–π': PatternFill(start_color='CCFFCC', end_color='CCFFCC', fill_type='solid'),
            '–°–ø—Ä–∞–≤–æ—á–Ω—ã–µ': PatternFill(start_color='CCCCFF', end_color='CCCCFF', fill_type='solid')
        }
        
        # –§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–µ—Ç–∞–ª—å–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
        worksheet = writer.sheets['–î–µ—Ç–∞–ª—å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ']
        
        # –ó–∞–≥–æ–ª–æ–≤–∫–∏
        header_fill = PatternFill(start_color='D3D3D3', end_color='D3D3D3', fill_type='solid')
        for col_idx in range(1, len(df.columns) + 1):
            cell = worksheet.cell(row=1, column=col_idx)
            cell.fill = header_fill
        
        # –¶–≤–µ—Ç–æ–≤–æ–µ –≤—ã–¥–µ–ª–µ–Ω–∏–µ —Å—Ç—Ä–æ–∫ –ø–æ –≥—Ä—É–ø–ø–∞–º
        group_column_idx = df.columns.get_loc('–¶–µ–ª–µ–≤–æ–π/–ù–µ —Ü–µ–ª–µ–≤–æ–π') + 1
        
        for row_idx in range(2, len(df) + 2):
            group_value = df.iloc[row_idx - 2]['–¶–µ–ª–µ–≤–æ–π/–ù–µ —Ü–µ–ª–µ–≤–æ–π']
            
            if group_value in colors:
                for col_idx in range(1, len(df.columns) + 1):
                    cell = worksheet.cell(row=row_idx, column=col_idx)
                    cell.fill = colors[group_value]
        
        # –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –∏–∑–º–µ–Ω–µ–Ω–∏–µ —à–∏—Ä–∏–Ω—ã —Å—Ç–æ–ª–±—Ü–æ–≤ –¥–ª—è –¥–µ—Ç–∞–ª—å–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
        self._auto_adjust_column_width(worksheet, df)
        
        # –§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Å–≤–æ–¥–Ω–æ–π —Ç–∞–±–ª–∏—Ü—ã (–¶–µ–ª–µ–≤—ã–µ)
        self._format_target_summary_table(writer, target_summary_df)
        
        # –§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Å–≤–æ–¥–Ω–æ–π —Ç–∞–±–ª–∏—Ü—ã (–°–ø—Ä–∞–≤–æ—á–Ω—ã–µ)
        self._format_reference_summary_table(writer, reference_summary_df)
    
    def _format_target_summary_table(self, writer, target_summary_df):
        """–§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Å–≤–æ–¥–Ω–æ–π —Ç–∞–±–ª–∏—Ü—ã —Ü–µ–ª–µ–≤—ã—Ö –∑–≤–æ–Ω–∫–æ–≤"""
        worksheet = writer.sheets['–°–≤–æ–¥–Ω–∞—è —Ç–∞–±–ª–∏—Ü–∞ (–¶–µ–ª–µ–≤—ã–µ)']
        
        # –¶–≤–µ—Ç–∞ —Å–æ–≥–ª–∞—Å–Ω–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—é
        light_green = PatternFill(start_color='CCFFCC', end_color='CCFFCC', fill_type='solid')  # –°–≤–µ—Ç–ª–æ-–∑–µ–ª–µ–Ω—ã–π
        light_red = PatternFill(start_color='FFCCCC', end_color='FFCCCC', fill_type='solid')    # –°–≤–µ—Ç–ª–æ-–∫—Ä–∞—Å–Ω—ã–π  
        light_orange = PatternFill(start_color='FFE4CC', end_color='FFE4CC', fill_type='solid') # –°–≤–µ—Ç–ª–æ-–æ—Ä–∞–Ω–∂–µ–≤—ã–π
        
        # –ó–∞–≥–æ–ª–æ–≤–∫–∏
        header_fill = PatternFill(start_color='D3D3D3', end_color='D3D3D3', fill_type='solid')
        for col_idx in range(1, len(target_summary_df.columns) + 1):
            cell = worksheet.cell(row=1, column=col_idx)
            cell.fill = header_fill
        
        # –ü—Ä–∏–º–µ–Ω—è–µ–º —Ü–≤–µ—Ç–∞ –∫ —Å—Ç—Ä–æ–∫–∞–º —Å–æ–≥–ª–∞—Å–Ω–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—é
        for row_idx in range(2, len(target_summary_df) + 2):
            category = target_summary_df.iloc[row_idx - 2]['–ö–∞—Ç–µ–≥–æ—Ä–∏—è']
            
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ü–≤–µ—Ç —Å—Ç—Ä–æ–∫–∏
            fill_color = None
            if '–ó–∞–ø–∏—Å–∞–Ω–Ω—ã–µ' in category:
                fill_color = light_green
            elif '–ù–µ –∑–∞–ø–∏—Å–∞–Ω–Ω—ã–µ' in category:
                fill_color = light_red
            elif '–ü–ï–†–ï–®–õ–ò –í –ú–ï–°–°–ï–ù–î–ñ–ï–†' in category:
                fill_color = light_green
            elif '–ü–ï–†–ï–ê–î–†–ï–°–ê–¶–ò–Ø' in category:
                fill_color = light_green
            elif '–ó–ê–ü–õ–ê–ù–ò–†–û–í–ê–ù –ü–ï–†–ï–ó–í–û–ù' in category:
                fill_color = light_green
            elif '–û–±—â–∞—è' in category:
                fill_color = light_red
            elif any(keyword in category for keyword in ['–°–í–û–ò –ó–ê–ü–ß–ê–°–¢–ò', '–ü–û–î–£–ú–ê–ï–¢/–û–¢–ö–ê–ó', '–ù–ï–¢ –í–†–ï–ú–ï–ù–ò/–ó–ê–ù–Ø–¢–û', '–í–´–°–û–ö–ê–Ø –°–¢–û–ò–ú–û–°–¢–¨', '–ù–ï –í–´–ü–û–õ–ù–Ø–ï–ú –†–ê–ë–û–¢–´']):
                fill_color = light_orange
            
            # –ü—Ä–∏–º–µ–Ω—è–µ–º —Ü–≤–µ—Ç –∫–æ –≤—Å–µ–π —Å—Ç—Ä–æ–∫–µ
            if fill_color:
                for col_idx in range(1, len(target_summary_df.columns) + 1):
                    cell = worksheet.cell(row=row_idx, column=col_idx)
                    cell.fill = fill_color
        
        # –ü—Ä–∏–º–µ–Ω—è–µ–º –æ–±—â—É—é —Ç–∞–±–ª–∏—á–Ω—É—é —Ä–∞—Å–∫–ª–∞–¥–∫—É (–≥—Ä–∞–Ω–∏—Ü—ã, –≤—ã—Ä–∞–≤–Ω–∏–≤–∞–Ω–∏–µ, —à–∏—Ä–∏–Ω–∞)
        self._apply_summary_table_layout(worksheet, target_summary_df)
    
    def _format_reference_summary_table(self, writer, reference_summary_df):
        """–§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Å–≤–æ–¥–Ω–æ–π —Ç–∞–±–ª–∏—Ü—ã —Å–ø—Ä–∞–≤–æ—á–Ω—ã—Ö –∑–≤–æ–Ω–∫–æ–≤"""
        worksheet = writer.sheets['–°–≤–æ–¥–Ω–∞—è —Ç–∞–±–ª–∏—Ü–∞ (–°–ø—Ä–∞–≤–æ—á–Ω—ã–µ)']
        
        # –ó–∞–≥–æ–ª–æ–≤–∫–∏
        header_fill = PatternFill(start_color='D3D3D3', end_color='D3D3D3', fill_type='solid')
        for col_idx in range(1, len(reference_summary_df.columns) + 1):
            cell = worksheet.cell(row=1, column=col_idx)
            cell.fill = header_fill
        
        # –ü—Ä–∏–º–µ–Ω—è–µ–º –æ–±—â—É—é —Ç–∞–±–ª–∏—á–Ω—É—é —Ä–∞—Å–∫–ª–∞–¥–∫—É
        self._apply_summary_table_layout(worksheet, reference_summary_df)

    def _apply_summary_table_layout(self, worksheet, dataframe):
        """–ï–¥–∏–Ω—ã–π —Å—Ç–∏–ª—å –¥–ª—è —Å–≤–æ–¥–Ω—ã—Ö —Ç–∞–±–ª–∏—Ü: –≥—Ä–∞–Ω–∏—Ü—ã, —Ü–µ–Ω—Ç—Ä–æ–≤–∫–∞ –∏ —É–∑–∫–∏–µ —Å—Ç–æ–ª–±—Ü—ã"""
        thin_side = Side(style='thin', color='000000')
        thin_border = Border(left=thin_side, right=thin_side, top=thin_side, bottom=thin_side)
        center_alignment = Alignment(horizontal='center', vertical='center', wrap_text=False)
        
        total_columns = len(dataframe.columns)
        column_widths = [40, 10] + [6] * max(0, total_columns - 2)
        
        for idx in range(total_columns):
            column_letter = get_column_letter(idx + 1)
            width = column_widths[idx] if idx < len(column_widths) else 6
            worksheet.column_dimensions[column_letter].width = width
        
        max_row = len(dataframe) + 1
        for row in worksheet.iter_rows(min_row=1, max_row=max_row, min_col=1, max_col=total_columns):
            for cell in row:
                cell.border = thin_border
                if cell.column == 1:
                    cell.alignment = Alignment(horizontal='left', vertical='center', wrap_text=False)
                else:
                    cell.alignment = center_alignment
    
    def _auto_adjust_column_width(self, worksheet, df):
        """–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –∏–∑–º–µ–Ω–µ–Ω–∏–µ —à–∏—Ä–∏–Ω—ã —Å—Ç–æ–ª–±—Ü–æ–≤ –¥–ª—è –ª—É—á—à–µ–π —á–∏—Ç–∞–µ–º–æ—Å—Ç–∏"""
        for col_idx, column in enumerate(df.columns, 1):
            # –ù–∞—Ö–æ–¥–∏–º –º–∞–∫—Å–∏–º–∞–ª—å–Ω—É—é –¥–ª–∏–Ω—É —Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ –≤ —Å—Ç–æ–ª–±—Ü–µ
            max_length = 0
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∑–∞–≥–æ–ª–æ–≤–æ–∫
            max_length = max(max_length, len(str(column)))
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –≤—Å–µ –∑–Ω–∞—á–µ–Ω–∏—è –≤ —Å—Ç–æ–ª–±—Ü–µ
            for value in df[column]:
                max_length = max(max_length, len(str(value)))
            
            # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —à–∏—Ä–∏–Ω—É —Å—Ç–æ–ª–±—Ü–∞ —Å –Ω–µ–±–æ–ª—å—à–∏–º –∑–∞–ø–∞—Å–æ–º
            # –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è —à–∏—Ä–∏–Ω–∞ 10, –º–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è 50 –¥–ª—è —á–∏—Ç–∞–µ–º–æ—Å—Ç–∏
            adjusted_width = min(max(max_length + 2, 10), 50)
            
            # –ü–æ–ª—É—á–∞–µ–º –±—É–∫–≤–µ–Ω–Ω–æ–µ –æ–±–æ–∑–Ω–∞—á–µ–Ω–∏–µ —Å—Ç–æ–ª–±—Ü–∞ (A, B, C, ...)
            column_letter = worksheet.cell(row=1, column=col_idx).column_letter
            
            # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —à–∏—Ä–∏–Ω—É —Å—Ç–æ–ª–±—Ü–∞
            worksheet.column_dimensions[column_letter].width = adjusted_width
